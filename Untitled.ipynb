{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cea4eeb4-e0e3-413f-b14a-5962a2b08662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ GradCAM imported successfully\n",
      "âœ“ Using device: cpu\n",
      "âœ“ Random seeds set for reproducibility\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup & Imports\n",
    "import os, random, re, json, gc, time, threading, warnings\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torchvision import transforms\n",
    "import timm\n",
    "\n",
    "import cv2\n",
    "try:\n",
    "    import pytesseract\n",
    "    # Set tesseract path for Windows - adjust if needed\n",
    "    if os.name == 'nt':  # Windows\n",
    "        pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "except ImportError:\n",
    "    print(\"Warning: pytesseract not available\")\n",
    "\n",
    "from jinja2 import Template\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import grad-cam with error handling\n",
    "try:\n",
    "    from pytorch_grad_cam import GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
    "    from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "    from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "    print(\"âœ“ GradCAM imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"âš ï¸ GradCAM import failed: {e}\")\n",
    "    print(\"Run: pip install grad-cam\")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set matplotlib style\n",
    "try:\n",
    "    plt.style.use('seaborn-v0_8')\n",
    "except OSError:\n",
    "    try:\n",
    "        plt.style.use('seaborn')\n",
    "    except OSError:\n",
    "        plt.style.use('default')\n",
    "        print(\"âš ï¸ Using default matplotlib style\")\n",
    "\n",
    "# Set up device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"âœ“ Using device: {device}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "print(\"âœ“ Random seeds set for reproducibility\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0a2344a-fa86-4e4d-872e-0ca4da9532dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset preparation starting...\n",
      "âœ“ Dataset already prepared\n",
      "âœ… Dataset preparation complete!\n",
      "ðŸ“ Dataset base: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\n",
      "ðŸ§  Train set: 965 files\n",
      "ðŸ§ª Val set: 208 files\n",
      "ðŸ§ª Test set: 208 files\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Dataset Preparation (Updated paths for your system)\n",
    "# Update this path to your actual dataset location\n",
    "BASE_DIR = Path(r\"C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\")\n",
    "REPORTS_DIR = BASE_DIR / 'generated_reports'\n",
    "MODELS_DIR = BASE_DIR / 'saved_models'\n",
    "TRAIN_DIR = BASE_DIR / 'train'\n",
    "VAL_DIR = BASE_DIR / 'val'\n",
    "TEST_DIR = BASE_DIR / 'test'\n",
    "\n",
    "# Create necessary directories\n",
    "for dir_path in [REPORTS_DIR, MODELS_DIR, TRAIN_DIR, VAL_DIR, TEST_DIR]:\n",
    "    dir_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Define your class folder names and their label prefixes\n",
    "SOURCE_DIRS_MAP = {\n",
    "    'Abnormal Heartbeat Patients': 'HB',\n",
    "    'Myocardial Infarction Patients': 'MI', \n",
    "    'Normal Person': 'Normal',\n",
    "    'Patient that have History of Myocardial Infraction': 'PMI'\n",
    "}\n",
    "\n",
    "print(\"Dataset preparation starting...\")\n",
    "\n",
    "# Check if data is already split\n",
    "if len(list(TRAIN_DIR.rglob('*.jpg'))) > 0:\n",
    "    print(\"âœ“ Dataset already prepared\")\n",
    "else:\n",
    "    print(\"Preparing dataset...\")\n",
    "    # Clean and collect all image paths\n",
    "    all_image_paths = []\n",
    "    class_to_prefix = {}\n",
    "\n",
    "    for src_folder_name, prefix in SOURCE_DIRS_MAP.items():\n",
    "        current_src_dir = BASE_DIR / src_folder_name\n",
    "        if not current_src_dir.exists():\n",
    "            print(f\"âš ï¸ Warning: Source directory '{current_src_dir}' does not exist. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"ðŸ“‚ Processing source directory: {current_src_dir}\")\n",
    "        for img_file in current_src_dir.iterdir():\n",
    "            if img_file.is_file() and img_file.suffix.lower() in ['.jpg', '.jpeg', '.png']:\n",
    "                if \"Copy\" in img_file.name:\n",
    "                    print(f\"ðŸ—‘ï¸ Removing duplicate file: {img_file}\")\n",
    "                    try:\n",
    "                        os.remove(img_file)\n",
    "                    except:\n",
    "                        pass\n",
    "                    continue\n",
    "                all_image_paths.append((img_file, src_folder_name))\n",
    "                class_to_prefix[src_folder_name] = prefix\n",
    "\n",
    "    if all_image_paths:\n",
    "        # Group by class and split\n",
    "        images_by_class = {cls: [] for cls in SOURCE_DIRS_MAP.keys()}\n",
    "        for img_path, cls in all_image_paths:\n",
    "            images_by_class[cls].append(img_path)\n",
    "\n",
    "        train_ratio = 0.7\n",
    "        val_ratio = 0.15\n",
    "        test_ratio = 0.15\n",
    "\n",
    "        for src_folder_name, img_list in images_by_class.items():\n",
    "            if not img_list:\n",
    "                continue\n",
    "\n",
    "            print(f\"ðŸ”€ Splitting class '{src_folder_name}' ({len(img_list)} images)...\")\n",
    "\n",
    "            class_train_dir = TRAIN_DIR / src_folder_name\n",
    "            class_val_dir = VAL_DIR / src_folder_name\n",
    "            class_test_dir = TEST_DIR / src_folder_name\n",
    "            for dir_path in [class_train_dir, class_val_dir, class_test_dir]:\n",
    "                dir_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "            train_images, temp_images = train_test_split(img_list, test_size=(val_ratio + test_ratio), random_state=42)\n",
    "            val_images, test_images = train_test_split(temp_images, test_size=(test_ratio / (val_ratio + test_ratio)), random_state=42)\n",
    "\n",
    "            print(f\"  ðŸ§ª Train: {len(train_images)} | Val: {len(val_images)} | Test: {len(test_images)}\")\n",
    "\n",
    "            def copy_and_rename(image_list, dest_dir, prefix_label):\n",
    "                for i, img_path in enumerate(image_list):\n",
    "                    new_name = f\"{prefix_label}({i+1}){img_path.suffix}\"\n",
    "                    try:\n",
    "                        shutil.copy(img_path, dest_dir / new_name)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error copying {img_path}: {e}\")\n",
    "\n",
    "            prefix_label = class_to_prefix[src_folder_name]\n",
    "            copy_and_rename(train_images, class_train_dir, prefix_label)\n",
    "            copy_and_rename(val_images, class_val_dir, prefix_label)\n",
    "            copy_and_rename(test_images, class_test_dir, prefix_label)\n",
    "\n",
    "print(\"âœ… Dataset preparation complete!\")\n",
    "print(f\"ðŸ“ Dataset base: {BASE_DIR}\")\n",
    "print(f\"ðŸ§  Train set: {len(list(TRAIN_DIR.rglob('*.jpg')))} files\")\n",
    "print(f\"ðŸ§ª Val set: {len(list(VAL_DIR.rglob('*.jpg')))} files\")\n",
    "print(f\"ðŸ§ª Test set: {len(list(TEST_DIR.rglob('*.jpg')))} files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8fd1535-a55f-4dd8-a648-c4b2fe5dac7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Enhanced Dataset Class\n",
    "class ECGImageDataset(Dataset):\n",
    "    label_map = {'HB': 0, 'MI': 1, 'Normal': 2, 'PMI': 3}\n",
    "\n",
    "    def __init__(self, root: Path, transform=None, is_training=False):\n",
    "        self.samples, self.transform, self.is_training = [], transform, is_training\n",
    "        self.class_counts = {i: 0 for i in self.label_map.values()}\n",
    "\n",
    "        for cls, idx in self.label_map.items():\n",
    "            pattern = rf'{cls}\\(\\d+\\)'\n",
    "            for p in root.rglob('*.jpg'):\n",
    "                if re.search(pattern, p.name):\n",
    "                    self.samples.append((p, idx))\n",
    "                    self.class_counts[idx] += 1\n",
    "\n",
    "        random.shuffle(self.samples)\n",
    "        print(f\"Dataset loaded: {len(self.samples)} samples\")\n",
    "        print(f\"Class distribution: {self.class_counts}\")\n",
    "\n",
    "    def get_class_weights(self):\n",
    "        \"\"\"Calculate class weights for balanced training\"\"\"\n",
    "        total = sum(self.class_counts.values())\n",
    "        weights = [total / (len(self.class_counts) * count) for count in self.class_counts.values()]\n",
    "        return torch.FloatTensor(weights)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.samples[idx]\n",
    "        try:\n",
    "            # Load image\n",
    "            img = Image.open(path).convert('RGB')\n",
    "            img_array = np.array(img)\n",
    "\n",
    "            # Apply transforms\n",
    "            if self.transform:\n",
    "                if isinstance(self.transform, A.Compose):\n",
    "                    # Albumentations\n",
    "                    transformed = self.transform(image=img_array)\n",
    "                    img_tensor = transformed['image']\n",
    "                else:\n",
    "                    # PyTorch transforms\n",
    "                    img_tensor = self.transform(img)\n",
    "            else:\n",
    "                img_tensor = transforms.ToTensor()(img)\n",
    "\n",
    "            return img_tensor, label, str(path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {path}: {e}\")\n",
    "            dummy_img = torch.zeros(3, 384, 384)\n",
    "            return dummy_img, label, str(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad62b360-7943-4123-a59b-0be3a62d16e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Data Augmentation\n",
    "def get_training_transforms():\n",
    "    \"\"\"Comprehensive augmentation for ECG images\"\"\"\n",
    "    return A.Compose([\n",
    "        # Geometric transforms\n",
    "        A.Resize(384, 384),\n",
    "        A.HorizontalFlip(p=0.3),\n",
    "        A.Rotate(limit=3, p=0.3),\n",
    "        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=2, p=0.3),\n",
    "\n",
    "        # Noise and artifacts\n",
    "        A.GaussNoise(var_limit=(5.0, 15.0), p=0.2),\n",
    "        A.ISONoise(color_shift=(0.01, 0.02), intensity=(0.1, 0.3), p=0.2),\n",
    "        A.MultiplicativeNoise(multiplier=(0.95, 1.05), p=0.2),\n",
    "\n",
    "        # Brightness/Contrast\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.3),\n",
    "        A.RandomGamma(gamma_limit=(90, 110), p=0.2),\n",
    "\n",
    "        # Grid artifacts\n",
    "        A.GridDistortion(num_steps=3, distort_limit=0.05, p=0.15),\n",
    "\n",
    "        # Normalize and convert to tensor\n",
    "        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "def get_validation_transforms():\n",
    "    \"\"\"Simple transforms for validation/test\"\"\"\n",
    "    return A.Compose([\n",
    "        A.Resize(384, 384),\n",
    "        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "        ToTensorV2()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2e76487-88d8-4a81-99a3-dd391f8f47ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating datasets...\n",
      "Dataset loaded: 1145 samples\n",
      "Class distribution: {0: 237, 1: 430, 2: 298, 3: 180}\n",
      "Dataset loaded: 247 samples\n",
      "Class distribution: {0: 51, 1: 93, 2: 64, 3: 39}\n",
      "Class weights: tensor([1.2078, 0.6657, 0.9606, 1.5903])\n",
      "Training batches: 72, Validation batches: 16\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Create Datasets and DataLoaders\n",
    "print(\"Creating datasets...\")\n",
    "train_ds = ECGImageDataset(TRAIN_DIR, transform=get_training_transforms(), is_training=True)\n",
    "val_ds = ECGImageDataset(VAL_DIR, transform=get_validation_transforms(), is_training=False)\n",
    "\n",
    "# Weighted Sampling for Class Balance\n",
    "class_weights = train_ds.get_class_weights()\n",
    "sample_weights = [class_weights[label] for _, label in train_ds.samples]\n",
    "sampler = WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)\n",
    "\n",
    "# Data loaders with optimal settings for local machine\n",
    "train_loader = DataLoader(train_ds, batch_size=16, sampler=sampler, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=16, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "print(f\"Class weights: {class_weights}\")\n",
    "print(f\"Training batches: {len(train_loader)}, Validation batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e62faf2-dc99-4a2e-95a9-9ecbae2262d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Enhanced Model Architecture\n",
    "class ECGClassifier(nn.Module):\n",
    "    def __init__(self, model_name='tf_efficientnetv2_s', num_classes=4, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(model_name, pretrained=True, num_classes=0)\n",
    "        self.feature_dim = self.backbone.num_features\n",
    "\n",
    "        # Enhanced classifier head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(self.feature_dim, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout/2),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "        # Initialize weights\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.classifier:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        return self.classifier(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a67ee8a-a209-4ed3-8613-adb322fa8daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Total parameters: 20,506,452\n",
      "Trainable parameters: 20,506,452\n",
      "Mixed precision training: Disabled\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Training Setup\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize model\n",
    "model = ECGClassifier(num_classes=4).to(device)\n",
    "\n",
    "# Print model info\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "# Loss function with class weighting\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights.to(device), label_smoothing=0.1)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=8e-4,\n",
    "    weight_decay=0.01,\n",
    "    betas=(0.9, 0.999)\n",
    ")\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=8e-4,\n",
    "    epochs=20,  # Reduced for local testing\n",
    "    steps_per_epoch=len(train_loader),\n",
    "    pct_start=0.1,\n",
    "    anneal_strategy='cos'\n",
    ")\n",
    "\n",
    "# Mixed precision training\n",
    "use_amp = device.type == 'cuda'\n",
    "scaler = torch.cuda.amp.GradScaler() if use_amp else None\n",
    "print(f\"Mixed precision training: {'Enabled' if use_amp else 'Disabled'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a89980a-d8a1-41dc-a618-55aa2a8fbda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Training Functions\n",
    "def train_epoch(model, loader, optimizer, scheduler, scaler, criterion, epoch, use_amp=True):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    \n",
    "    for batch_idx, (imgs, labels, _) in enumerate(loader):\n",
    "        imgs, labels = imgs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Mixed precision forward pass\n",
    "        if use_amp and scaler is not None:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Update scheduler if it's OneCycleLR\n",
    "        if isinstance(scheduler, torch.optim.lr_scheduler.OneCycleLR):\n",
    "            scheduler.step()\n",
    "        \n",
    "        # Statistics\n",
    "        total_loss += loss.item() * imgs.size(0)\n",
    "        predicted = outputs.argmax(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        # Progress logging\n",
    "        if batch_idx % 20 == 0:\n",
    "            lr = optimizer.param_groups[0]['lr']\n",
    "            print(f'Epoch {epoch} [{batch_idx}/{len(loader)}] '\n",
    "                  f'Loss: {loss.item():.4f} Acc: {100.*correct/total:.2f}% LR: {lr:.6f}')\n",
    "    \n",
    "    return total_loss/total, correct/total\n",
    "\n",
    "def validate_epoch(model, loader, criterion, use_amp=True):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    all_preds, all_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for imgs, labels, _ in loader:\n",
    "            imgs, labels = imgs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "            \n",
    "            # Mixed precision validation\n",
    "            if use_amp:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    outputs = model(imgs)\n",
    "                    loss = criterion(outputs.float(), labels)\n",
    "            else:\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item() * imgs.size(0)\n",
    "            predicted = outputs.argmax(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    return total_loss/total, correct/total, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c7cc9bc-5605-4e06-a95f-463e9bc2fb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Training Loop\n",
    "def train_model(model, train_loader, val_loader, optimizer, scheduler, scaler, criterion, epochs=20, patience=5):\n",
    "    best_acc = 0\n",
    "    no_improve = 0\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accs, val_accs = [], []\n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        try:\n",
    "            # Training\n",
    "            train_loss, train_acc = train_epoch(model, train_loader, optimizer, scheduler, scaler, criterion, epoch, use_amp)\n",
    "            \n",
    "            # Validation\n",
    "            val_loss, val_acc, val_preds, val_labels = validate_epoch(model, val_loader, criterion, use_amp)\n",
    "            \n",
    "            # Save metrics\n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "            train_accs.append(train_acc)\n",
    "            val_accs.append(val_acc)\n",
    "            \n",
    "            print(f\"\\nEpoch {epoch}/{epochs}\")\n",
    "            print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "            print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            # Save best model\n",
    "            if val_acc > best_acc:\n",
    "                best_acc = val_acc\n",
    "                no_improve = 0\n",
    "                \n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'scheduler_state_dict': scheduler.state_dict(),\n",
    "                    'best_acc': best_acc,\n",
    "                    'train_losses': train_losses,\n",
    "                    'val_losses': val_losses,\n",
    "                    'train_accs': train_accs,\n",
    "                    'val_accs': val_accs,\n",
    "                    'model_config': {\n",
    "                        'num_classes': 4,\n",
    "                        'model_name': 'tf_efficientnetv2_s'\n",
    "                    }\n",
    "                }, MODELS_DIR / 'best_ecg_model.pth')\n",
    "                \n",
    "                print(f\"âœ… New best model saved! Validation Accuracy: {best_acc:.4f}\")\n",
    "            else:\n",
    "                no_improve += 1\n",
    "            \n",
    "            # Early stopping\n",
    "            if no_improve >= patience:\n",
    "                print(f\"Early stopping after {epoch} epochs\")\n",
    "                break\n",
    "                \n",
    "            # Memory cleanup\n",
    "            if epoch % 3 == 0:\n",
    "                gc.collect()\n",
    "                if device.type == 'cuda':\n",
    "                    torch.cuda.empty_cache()\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error in epoch {epoch}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return {\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'train_accs': train_accs,\n",
    "        'val_accs': val_accs,\n",
    "        'best_acc': best_acc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340d7b03-f82a-4a6a-ace8-fa6da1409662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training with reduced epochs for local testing...\n",
      "Starting training...\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Run Training\n",
    "print(\"Starting training with reduced epochs for local testing...\")\n",
    "results = train_model(model, train_loader, val_loader, optimizer, scheduler, scaler, criterion, epochs=10, patience=3)\n",
    "\n",
    "print(\"âœ… Training complete!\")\n",
    "print(f\"Best validation accuracy: {results['best_acc']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54b848f-e040-45e9-a35e-b1f0df3dc0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Visualization\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Loss curves\n",
    "epochs_range = range(1, len(results['train_losses']) + 1)\n",
    "ax1.plot(epochs_range, results['train_losses'], label='Training Loss', color='blue', linewidth=2)\n",
    "ax1.plot(epochs_range, results['val_losses'], label='Validation Loss', color='red', linewidth=2)\n",
    "ax1.set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy curves\n",
    "ax2.plot(epochs_range, results['train_accs'], label='Training Accuracy', color='blue', linewidth=2)\n",
    "ax2.plot(epochs_range, results['val_accs'], label='Validation Accuracy', color='red', linewidth=2)\n",
    "ax2.set_title('Training and Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Training summary\n",
    "ax3.text(0.1, 0.8, f'Best Validation Accuracy: {results[\"best_acc\"]:.4f}',\n",
    "         fontsize=12, transform=ax3.transAxes, fontweight='bold')\n",
    "ax3.text(0.1, 0.7, f'Final Training Accuracy: {results[\"train_accs\"][-1]:.4f}',\n",
    "         fontsize=12, transform=ax3.transAxes)\n",
    "ax3.text(0.1, 0.6, f'Final Validation Accuracy: {results[\"val_accs\"][-1]:.4f}',\n",
    "         fontsize=12, transform=ax3.transAxes)\n",
    "ax3.text(0.1, 0.5, f'Total Epochs: {len(results[\"train_losses\"])}',\n",
    "         fontsize=12, transform=ax3.transAxes)\n",
    "ax3.set_title('Training Summary', fontsize=14, fontweight='bold')\n",
    "ax3.axis('off')\n",
    "\n",
    "# Clear the fourth subplot\n",
    "ax4.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbf6ea9-fdbe-43a6-b22e-4db1c73c8188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Model Evaluation\n",
    "print(\"Loading best model for evaluation...\")\n",
    "\n",
    "model_path = MODELS_DIR / 'best_ecg_model.pth'\n",
    "if model_path.exists():\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"âœ… Model loaded successfully!\")\n",
    "    print(f\"Best validation accuracy: {checkpoint['best_acc']:.4f}\")\n",
    "else:\n",
    "    print(\"Using current model state for evaluation...\")\n",
    "\n",
    "# Final evaluation\n",
    "print(\"\\nEvaluating model on validation set...\")\n",
    "val_loss, val_acc, y_pred, y_true = validate_epoch(model, val_loader, criterion, use_amp)\n",
    "\n",
    "# Classification report\n",
    "label_names = ['Abnormal HB', 'MI', 'Normal', 'PMI']\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL CLASSIFICATION REPORT\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_true, y_pred, target_names=label_names, digits=4))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=label_names, yticklabels=label_names,\n",
    "            cbar_kws={'label': 'Count'})\n",
    "plt.title('Confusion Matrix - ECG Classification', fontsize=16, fontweight='bold')\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸŽ¯ Model evaluation complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cb2e26-5427-434b-8e50-b74dd7f45636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Generate Sample Reports\n",
    "from datetime import datetime\n",
    "\n",
    "class_map = {\n",
    "    0: (\"Abnormal Heartbeat\", \"Possible arrhythmia or irregular rhythm. Recommend further cardiological evaluation.\"),\n",
    "    1: (\"Myocardial Infarction\", \"ECG pattern consistent with myocardial infarction. Urgent clinical attention advised.\"),\n",
    "    2: (\"Normal Sinus Rhythm\", \"Normal ECG. No abnormalities detected.\"),\n",
    "    3: (\"History of Myocardial Infarction\", \"Signs of previous infarction. Regular follow-up recommended.\")\n",
    "}\n",
    "\n",
    "def generate_text_report(test_id, prediction_idx, save_dir):\n",
    "    date_str = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    diagnosis, interpretation = class_map[prediction_idx]\n",
    "\n",
    "    content = f\"\"\"Test ID: {test_id}\n",
    "Date: {date_str}\n",
    "\n",
    "Automated Diagnosis\n",
    "-------------------\n",
    "{diagnosis}\n",
    "\n",
    "Clinical Interpretation\n",
    "-----------------------\n",
    "{interpretation}\n",
    "\"\"\"\n",
    "\n",
    "    report_path = save_dir / f\"{test_id}.txt\"\n",
    "    with open(report_path, 'w') as f:\n",
    "        f.write(content)\n",
    "    return diagnosis\n",
    "\n",
    "# Generate sample reports\n",
    "test_ds = ECGImageDataset(TEST_DIR, transform=get_validation_transforms())\n",
    "test_loader = DataLoader(test_ds, batch_size=1, shuffle=False, num_workers=1)\n",
    "\n",
    "REPORTS_DIR.mkdir(exist_ok=True)\n",
    "summary_data = []\n",
    "\n",
    "model.eval()\n",
    "print(\"Generating sample reports...\")\n",
    "\n",
    "sample_count = 0\n",
    "max_samples = 10  # Limit for demo\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img, _, path_str in test_loader:\n",
    "        if sample_count >= max_samples:\n",
    "            break\n",
    "            \n",
    "        img = img.to(device)\n",
    "        path = Path(path_str[0])\n",
    "        test_id = path.stem\n",
    "\n",
    "        start_time = time.time()\n",
    "        output = model(img)\n",
    "        pred_idx = output.argmax(1).item()\n",
    "        end_time = time.time()\n",
    "        \n",
    "        exec_time = round(end_time - start_time, 4)\n",
    "        diagnosis = generate_text_report(test_id, pred_idx, REPORTS_DIR)\n",
    "        \n",
    "        summary_data.append({\n",
    "            \"Test ID\": test_id,\n",
    "            \"Prediction Class\": pred_idx,\n",
    "            \"Diagnosis\": class_map[pred_idx][0],\n",
    "            \"Execution Time (s)\": exec_time\n",
    "        })\n",
    "        \n",
    "        sample_count += 1\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_df.to_csv(REPORTS_DIR / \"ecg_summary.csv\", index=False)\n",
    "print(f\"âœ… Generated {len(summary_data)} sample reports\")\n",
    "print(f\"Reports saved in: {REPORTS_DIR}\")\n",
    "\n",
    "print(\"\\nðŸŽ‰ Notebook execution complete!\")\n",
    "print(f\"ðŸ“Š Final Results:\")\n",
    "print(f\"   - Best Validation Accuracy: {results['best_acc']:.4f}\")\n",
    "print(f\"   - Total Training Epochs: {len(results['train_losses'])}\")\n",
    "print(f\"   - Model saved at: {MODELS_DIR / 'best_ecg_model.pth'}\")\n",
    "print(f\"   - Reports generated: {len(summary_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa24bd2-19a3-4732-a843-11634406dce2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
