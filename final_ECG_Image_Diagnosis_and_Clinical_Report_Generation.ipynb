{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQywnYYd-zae"
   },
   "source": [
    "# End-to-End Deep Learning Framework for Automated ECG Image Diagnosis and Clinical Report Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rIwmTM0B0P6C",
    "outputId": "41e90ddf-4860-4309-bfa8-7414b9135049"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timm in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (1.0.19)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (3.1.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: albumentations in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (2.0.8)\n",
      "Requirement already satisfied: grad-cam in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (1.5.5)\n",
      "Requirement already satisfied: pytesseract in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: torch in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from timm) (2.7.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from timm) (0.22.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from timm) (6.0.2)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from timm) (0.34.3)\n",
      "Requirement already satisfied: safetensors in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from timm) (0.5.3)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from scikit-learn) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from jinja2) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: pydantic>=2.9.2 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from albumentations) (2.10.3)\n",
      "Requirement already satisfied: albucore==0.0.24 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from albumentations) (0.0.24)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from albumentations) (4.12.0.88)\n",
      "Requirement already satisfied: stringzilla>=3.10.4 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from albucore==0.0.24->albumentations) (3.12.5)\n",
      "Requirement already satisfied: simsimd>=5.9.2 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from albucore==0.0.24->albumentations) (6.5.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from grad-cam) (11.1.0)\n",
      "Requirement already satisfied: ttach in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from grad-cam) (0.0.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from grad-cam) (4.67.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from grad-cam) (3.10.0)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from pytesseract) (24.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from pydantic>=2.9.2->albumentations) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from pydantic>=2.9.2->albumentations) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from pydantic>=2.9.2->albumentations) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from torch->timm) (3.17.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from torch->timm) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from torch->timm) (3.4.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from torch->timm) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from torch->timm) (72.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch->timm) (1.3.0)\n",
      "Requirement already satisfied: requests in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from huggingface_hub->timm) (2.32.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from tqdm->grad-cam) (0.4.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from matplotlib->grad-cam) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from matplotlib->grad-cam) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from matplotlib->grad-cam) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from matplotlib->grad-cam) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from matplotlib->grad-cam) (3.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from requests->huggingface_hub->timm) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from requests->huggingface_hub->timm) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from requests->huggingface_hub->timm) (2025.7.14)\n",
      "✓ GradCAM imported successfully\n",
      "✓ Using device: cpu\n",
      "✓ Random seeds set for reproducibility\n",
      "\n",
      "=== Import Verification ===\n",
      "✓ PyTorch version: 2.7.1+cpu\n",
      "✓ Timm version: 1.0.19\n",
      "✓ OpenCV version: 4.12.0\n",
      "✓ NumPy version: 2.1.3\n",
      "✓ Pandas version: 2.2.3\n",
      "✓ Tesseract OCR is working\n",
      "=== Setup Complete ===\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Setup & Imports\n",
    "\n",
    "# Install required packages with correct names and dependencies\n",
    "# Python packages only (Windows)\n",
    "!pip install timm scikit-learn jinja2 pandas opencv-python albumentations grad-cam pytesseract\n",
    "!pip install grad-cam --quiet  \n",
    "!pip install pytesseract --quiet  \n",
    "# Manually set path to tesseract.exe if you're on Windows\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "import os, random, re, json, gc, time, threading, warnings\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torchvision import transforms\n",
    "import timm\n",
    "\n",
    "import cv2\n",
    "import pytesseract\n",
    "from jinja2 import Template\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import grad-cam with correct syntax\n",
    "try:\n",
    "    from pytorch_grad_cam import GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
    "    from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "    from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "    print(\"✓ GradCAM imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"⚠️ GradCAM import failed: {e}\")\n",
    "    print(\"Installing grad-cam...\")\n",
    "    !pip install grad-cam\n",
    "    from pytorch_grad_cam import GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
    "    from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "    from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check if seaborn style exists, use alternative if not\n",
    "try:\n",
    "    plt.style.use('seaborn-v0_8')\n",
    "except OSError:\n",
    "    try:\n",
    "        plt.style.use('seaborn')\n",
    "    except OSError:\n",
    "        plt.style.use('default')\n",
    "        print(\"⚠️ Using default matplotlib style\")\n",
    "\n",
    "# Set up device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"✓ Using device: {device}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "print(\"✓ Random seeds set for reproducibility\")\n",
    "\n",
    "# Verify critical imports\n",
    "print(\"\\n=== Import Verification ===\")\n",
    "print(f\"✓ PyTorch version: {torch.__version__}\")\n",
    "print(f\"✓ Timm version: {timm.__version__}\")\n",
    "print(f\"✓ OpenCV version: {cv2.__version__}\")\n",
    "print(f\"✓ NumPy version: {np.__version__}\")\n",
    "print(f\"✓ Pandas version: {pd.__version__}\")\n",
    "\n",
    "# Test pytesseract\n",
    "try:\n",
    "    pytesseract.get_tesseract_version()\n",
    "    print(\"✓ Tesseract OCR is working\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Tesseract issue: {e}\")\n",
    "\n",
    "print(\"=== Setup Complete ===\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2psL62-j0UUy",
    "outputId": "a97386e5-a698-4d80-d296-d7082414a386"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dataset preparation...\n",
      "📂 Processing source directory: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(1) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(10) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(100) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(101) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(102) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(103) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(104) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(105) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(106) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(107) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(108) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(109) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(11) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(110) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(111) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(112) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(113) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(114) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(115) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(116) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(117) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(118) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(119) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(12) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(120) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(121) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(122) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(123) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(124) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(125) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(126) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(127) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(128) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(129) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(13) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(130) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(131) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(132) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(133) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(134) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(135) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(136) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(137) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(138) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(139) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(14) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(140) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(141) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(142) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(143) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(144) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(145) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(146) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(147) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(148) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(149) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(15) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(15) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(150) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(151) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(152) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(153) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(154) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(155) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(156) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(157) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(158) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(159) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(16) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(16) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(160) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(161) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(162) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(163) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(164) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(165) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(166) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(167) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(168) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(169) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(17) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(17) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(170) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(171) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(172) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(173) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(174) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(175) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(176) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(177) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(178) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(179) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(18) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(18) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(180) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(181) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(182) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(183) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(184) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(185) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(186) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(187) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(188) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(189) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(19) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(19) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(190) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(191) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(192) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(193) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(194) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(195) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(196) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(197) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(198) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(199) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(2) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(20) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(20) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(200) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(201) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(202) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(203) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(204) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(205) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(206) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(207) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(208) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(209) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(21) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(210) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(211) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(212) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(213) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(214) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(215) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(216) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(217) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(218) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(219) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(22) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(22) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(220) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(221) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(222) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(223) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(224) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(225) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(226) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(227) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(228) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(229) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(23) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(23) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(230) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(231) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(232) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(233) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(234) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(235) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(236) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(237) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(238) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(239) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(24) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(24) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(240) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(241) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(242) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(243) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(244) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(245) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(246) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(247) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(248) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(249) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(25) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(25) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(250) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(251) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(252) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(253) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(254) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(255) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(256) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(257) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(258) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(259) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(26) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(26) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(260) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(261) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(262) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(263) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(264) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(265) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(266) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(267) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(268) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(269) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(27) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(27) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(270) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(271) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(272) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(273) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(274) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(275) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(276) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(277) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(278) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(279) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(28) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(280) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(281) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(282) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(283) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(284) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(285) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(286) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(287) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(288) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(289) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(29) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(29) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(290) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(291) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(292) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(292) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(293) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(293) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(294) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(295) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(296) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(297) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(298) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(299) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(299) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(3) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(30) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(30) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(300) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(300) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(301) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(302) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(303) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(304) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(305) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(306) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(306) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(307) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(307) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(308) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(309) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(31) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(31) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(310) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(311) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(312) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(313) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(313) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(314) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(314) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(315) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(316) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(317) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(318) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(319) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(32) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(32) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(320) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(320) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(321) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(321) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(322) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(323) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(324) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(325) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(326) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(327) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(327) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(328) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(328) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(329) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(33) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(33) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(330) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(331) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(332) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(333) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(334) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(334) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(335) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(335) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(336) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(337) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(338) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(339) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(34) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(34) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(340) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(341) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(342) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(343) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(344) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(345) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(346) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(347) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(348) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(349) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(35) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(350) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(351) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(352) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(353) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(354) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(355) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(356) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(357) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(358) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(359) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(36) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(36) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(360) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(361) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(362) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(363) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(364) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(365) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(366) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(367) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(368) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(369) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(37) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(37) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(370) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(371) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(372) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(373) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(374) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(375) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(376) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(377) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(378) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(379) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(38) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(38) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(380) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(381) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(382) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(383) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(384) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(385) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(386) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(387) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(388) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(389) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(39) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(39) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(390) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(391) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(392) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(393) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(394) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(395) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(396) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(397) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(398) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(399) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(4) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(40) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(40) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(400) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(401) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(402) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(403) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(404) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(405) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(406) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(407) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(41) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(41) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(42) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(43) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(43) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(44) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(44) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(45) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(45) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(46) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(46) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(47) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(47) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(48) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(48) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(49) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(5) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(50) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(50) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(51) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(51) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(52) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(52) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(53) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(53) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(54) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(54) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(55) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(55) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(56) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(57) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(57) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(58) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(58) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(59) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(59) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(6) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(60) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(60) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(61) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(61) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(62) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(62) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(63) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(64) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(64) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(65) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(65) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(66) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(66) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(67) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(67) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(68) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(68) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(69) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(69) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(7) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(70) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(71) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(71) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(72) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(72) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(73) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(73) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(74) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(74) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(75) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(75) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(76) - Copy - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(76) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(77) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(78) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(79) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(8) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(80) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(81) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(82) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(83) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(84) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(85) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(86) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(87) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(88) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(89) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(9) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(90) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(91) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(92) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(93) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(94) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(95) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(96) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(97) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(98) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Abnormal Heartbeat Patients\\HB(99) - Copy.jpg\n",
      "📂 Processing source directory: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(1) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(10) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(100) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(101) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(102) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(103) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(104) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(105) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(106) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(107) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(108) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(109) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(11) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(110) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(111) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(112) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(113) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(114) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(115) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(116) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(117) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(118) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(119) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(12) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(120) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(121) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(122) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(123) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(124) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(125) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(126) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(127) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(128) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(129) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(13) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(130) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(131) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(132) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(133) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(134) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(135) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(136) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(137) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(138) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(139) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(14) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(140) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(141) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(142) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(143) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(144) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(145) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(146) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(147) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(148) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(149) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(15) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(150) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(151) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(152) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(153) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(154) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(155) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(156) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(157) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(158) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(159) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(16) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(160) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(161) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(162) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(163) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(164) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(165) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(166) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(167) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(168) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(169) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(17) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(170) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(171) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(172) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(173) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(174) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(175) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(176) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(177) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(178) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(179) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(18) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(180) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(181) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(182) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(183) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(184) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(185) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(186) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(187) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(188) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(189) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(19) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(190) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(191) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(192) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(193) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(194) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(195) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(196) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(197) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(198) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(199) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(2) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(20) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(200) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(201) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(202) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(203) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(204) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(205) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(206) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(207) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(208) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(209) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(21) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(210) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(211) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(212) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(213) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(214) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(216) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(217) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(218) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(219) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(22) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(220) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(221) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(222) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(223) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(224) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(225) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(226) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(227) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(228) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(229) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(23) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(230) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(231) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(232) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(233) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(234) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(235) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(236) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(237) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(238) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(239) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(24) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(240) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(241) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(243) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(245) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(247) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(249) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(25) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(251) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(253) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(255) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(257) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(259) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(26) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(261) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(263) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(265) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(267) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(269) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(27) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(271) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(273) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(275) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(277) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(279) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(28) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(281) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(283) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(285) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(287) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(289) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(29) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(291) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(293) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(295) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(297) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(299) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(3) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(30) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(301) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(303) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(305) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(307) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(309) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(31) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(311) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(313) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(315) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(317) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(319) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(32) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(321) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(323) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(325) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(327) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(329) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(33) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(331) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(333) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(335) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(337) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(339) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(34) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(341) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(343) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(345) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(347) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(349) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(35) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(351) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(353) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(355) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(357) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(359) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(36) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(361) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(363) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(365) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(367) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(369) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(37) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(371) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(373) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(375) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(377) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(379) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(38) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(381) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(383) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(385) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(387) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(389) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(39) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(391) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(393) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(395) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(397) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(399) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(4) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(40) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(401) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(403) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(405) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(407) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(409) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(41) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(411) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(413) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(415) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(417) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(419) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(42) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(421) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(423) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(425) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(427) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(429) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(43) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(431) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(433) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(435) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(437) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(439) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(44) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(441) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(443) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(445) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(447) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(449) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(45) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(451) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(453) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(457) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(459) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(46) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(461) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(463) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(465) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(467) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(469) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(47) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(471) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(473) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(475) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(477) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(479) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(48) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(49) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(5) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(50) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(51) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(52) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(53) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(54) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(55) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(56) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(57) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(58) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(59) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(6) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(60) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(61) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(62) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(63) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(64) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(65) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(66) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(67) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(68) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(69) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(7) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(70) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(71) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(72) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(73) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(74) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(75) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(76) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(77) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(78) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(79) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(8) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(80) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(81) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(82) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(83) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(84) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(85) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(86) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(87) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(88) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(89) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(9) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(90) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(91) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(92) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(93) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(94) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(95) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(96) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(97) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(98) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Myocardial Infarction Patients\\MI(99) - Copy.jpg\n",
      "📂 Processing source directory: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(1) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(10) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(100) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(101) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(102) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(103) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(104) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(105) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(106) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(107) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(108) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(109) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(11) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(110) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(111) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(112) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(113) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(114) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(115) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(116) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(117) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(118) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(119) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(12) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(120) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(121) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(122) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(123) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(124) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(125) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(126) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(127) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(128) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(129) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(13) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(130) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(131) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(132) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(133) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(134) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(135) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(136) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(137) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(138) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(139) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(14) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(140) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(141) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(142) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(143) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(144) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(145) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(146) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(147) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(148) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(149) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(15) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(150) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(151) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(152) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(153) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(154) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(155) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(156) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(157) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(158) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(159) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(16) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(160) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(161) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(162) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(163) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(164) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(165) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(166) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(167) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(168) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(169) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(17) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(170) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(171) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(172) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(173) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(174) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(175) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(176) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(177) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(178) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(179) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(18) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(180) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(181) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(182) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(183) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(184) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(185) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(186) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(187) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(188) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(189) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(19) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(190) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(191) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(192) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(193) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(194) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(195) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(196) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(197) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(198) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(199) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(2) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(20) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(200) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(201) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(202) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(203) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(204) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(205) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(206) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(207) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(208) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(209) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(21) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(210) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(211) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(212) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(213) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(214) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(215) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(216) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(217) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(218) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(219) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(22) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(220) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(221) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(222) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(223) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(224) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(225) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(226) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(227) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(228) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(229) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(23) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(230) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(231) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(232) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(233) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(234) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(235) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(236) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(237) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(238) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(239) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(24) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(240) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(241) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(242) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(243) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(244) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(245) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(246) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(247) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(248) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(249) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(25) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(250) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(251) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(252) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(253) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(254) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(255) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(256) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(257) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(258) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(259) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(26) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(260) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(261) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(262) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(263) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(264) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(265) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(266) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(267) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(268) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(269) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(27) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(270) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(271) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(272) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(273) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(274) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(275) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(276) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(277) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(278) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(279) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(28) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(280) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(281) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(282) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(283) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(284) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(285) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(287) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(289) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(29) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(291) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(293) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(295) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(297) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(299) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(3) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(30) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(301) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(303) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(305) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(307) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(309) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(31) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(311) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(313) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(315) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(317) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(319) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(32) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(321) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(323) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(325) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(327) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(329) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(33) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(331) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(333) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(335) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(337) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(339) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(34) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(341) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(343) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(345) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(347) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(349) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(35) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(351) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(353) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(355) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(357) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(359) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(36) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(361) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(363) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(365) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(367) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(369) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(37) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(371) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(373) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(375) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(377) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(379) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(38) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(381) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(383) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(385) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(387) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(389) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(39) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(391) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(393) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(395) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(397) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(399) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(4) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(40) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(401) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(403) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(405) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(407) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(409) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(41) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(411) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(413) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(415) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(417) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(419) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(42) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(421) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(423) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(425) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(427) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(429) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(43) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(431) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(433) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(435) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(437) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(439) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(44) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(441) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(443) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(445) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(447) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(449) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(45) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(451) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(453) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(455) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(457) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(459) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(46) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(461) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(463) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(465) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(467) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(469) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(47) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(471) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(473) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(475) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(477) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(479) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(48) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(481) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(483) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(485) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(487) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(489) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(49) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(491) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(493) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(495) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(497) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(499) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(5) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(50) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(501) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(503) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(505) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(507) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(509) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(51) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(511) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(513) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(515) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(517) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(519) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(52) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(521) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(523) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(525) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(527) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(529) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(53) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(531) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(533) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(535) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(537) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(539) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(54) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(541) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(543) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(545) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(547) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(549) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(55) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(551) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(553) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(555) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(557) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(559) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(56) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(561) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(563) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(565) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(567) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(57) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(58) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(59) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(6) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(60) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(61) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(62) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(63) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(64) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(65) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(66) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(67) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(68) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(69) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(7) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(70) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(71) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(72) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(73) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(74) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(75) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(76) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(77) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(78) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(79) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(8) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(80) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(81) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(82) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(83) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(84) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(85) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(86) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(87) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(88) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(89) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(9) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(90) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(91) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(92) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(93) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(94) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(95) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(96) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(97) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(98) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Normal Person\\Normal(99) - Copy.jpg\n",
      "📂 Processing source directory: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(1) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(10) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(100) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(101) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(102) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(103) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(104) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(105) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(106) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(107) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(108) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(109) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(11) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(110) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(111) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(112) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(113) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(114) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(115) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(116) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(117) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(118) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(119) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(12) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(120) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(121) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(122) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(123) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(124) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(125) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(126) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(127) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(128) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(129) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(13) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(130) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(131) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(132) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(133) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(134) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(135) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(136) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(137) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(138) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(139) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(14) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(140) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(141) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(142) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(143) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(144) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(145) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(146) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(147) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(148) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(149) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(15) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(150) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(151) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(152) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(153) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(154) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(155) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(156) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(157) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(158) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(159) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(16) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(160) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(161) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(162) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(163) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(164) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(165) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(166) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(167) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(168) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(169) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(17) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(170) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(171) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(172) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(173) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(175) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(177) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(179) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(18) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(181) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(183) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(185) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(187) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(189) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(19) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(191) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(193) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(195) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(197) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(199) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(2) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(20) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(201) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(203) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(205) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(207) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(209) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(21) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(211) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(213) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(215) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(217) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(219) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(22) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(221) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(223) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(225) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(227) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(229) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(23) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(231) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(233) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(235) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(237) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(239) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(24) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(241) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(243) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(245) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(247) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(249) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(25) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(251) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(253) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(255) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(257) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(259) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(26) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(261) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(263) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(265) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(267) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(269) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(27) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(271) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(273) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(275) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(277) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(279) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(28) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(281) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(283) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(285) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(287) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(289) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(29) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(291) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(293) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(295) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(297) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(299) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(3) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(30) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(301) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(303) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(305) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(307) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(309) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(31) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(311) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(313) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(315) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(317) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(319) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(32) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(321) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(323) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(325) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(327) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(329) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(33) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(331) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(333) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(335) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(337) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(339) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(34) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(341) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(343) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(35) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(36) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(37) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(38) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(39) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(4) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(40) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(41) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(42) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(43) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(44) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(45) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(46) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(47) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(48) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(49) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(5) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(50) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(51) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(52) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(53) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(54) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(55) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(56) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(57) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(58) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(59) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(6) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(60) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(61) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(62) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(63) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(64) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(65) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(66) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(67) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(68) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(69) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(7) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(70) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(71) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(72) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(73) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(74) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(75) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(76) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(77) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(78) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(79) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(8) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(80) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(81) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(82) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(83) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(84) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(85) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(86) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(87) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(88) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(89) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(9) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(90) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(91) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(92) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(93) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(94) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(95) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(96) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(97) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(98) - Copy.jpg\n",
      "🗑️ Removing duplicate file: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\\Patient that have History of Myocardial Infraction\\PMI(99) - Copy.jpg\n",
      "\n",
      "🔀 Splitting class 'Abnormal Heartbeat Patients' (339 images)...\n",
      "  🧪 Train: 237 | Val: 51 | Test: 51\n",
      "\n",
      "🔀 Splitting class 'Myocardial Infarction Patients' (358 images)...\n",
      "  🧪 Train: 250 | Val: 54 | Test: 54\n",
      "\n",
      "🔀 Splitting class 'Normal Person' (426 images)...\n",
      "  🧪 Train: 298 | Val: 64 | Test: 64\n",
      "\n",
      "🔀 Splitting class 'Patient that have History of Myocardial Infraction' (258 images)...\n",
      "  🧪 Train: 180 | Val: 39 | Test: 39\n",
      "\n",
      "✅ Dataset preparation complete!\n",
      "📁 Dataset base: C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\n",
      "🧠 Train set: 965 files\n",
      "🧪 Val set: 208 files\n",
      "🧪 Test set: 208 files\n"
     ]
    }
   ],
   "source": [
    "#2 preprocessing\n",
    "from pathlib import Path\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# === [1] Set your local dataset path ===\n",
    "# Example: Place all class folders inside \"./Dataset\"\n",
    "BASE_DIR = Path(r\"C:\\Users\\ahmed\\Downloads\\Telegram Desktop\\Dataset\\Dataset\")\n",
    "REPORTS_DIR = BASE_DIR / 'generated_reports'\n",
    "MODELS_DIR = BASE_DIR / 'saved_models'\n",
    "TRAIN_DIR = BASE_DIR / 'train'\n",
    "VAL_DIR = BASE_DIR / 'val'\n",
    "TEST_DIR = BASE_DIR / 'test'\n",
    "\n",
    "# Create necessary directories\n",
    "REPORTS_DIR.mkdir(exist_ok=True)\n",
    "MODELS_DIR.mkdir(exist_ok=True)\n",
    "TRAIN_DIR.mkdir(exist_ok=True)\n",
    "VAL_DIR.mkdir(exist_ok=True)\n",
    "TEST_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# === [2] Define your class folder names and their label prefixes ===\n",
    "SOURCE_DIRS_MAP = {\n",
    "    'Abnormal Heartbeat Patients': 'HB',\n",
    "    'Myocardial Infarction Patients': 'MI',\n",
    "    'Normal Person': 'Normal',\n",
    "    'Patient that have History of Myocardial Infraction': 'PMI'\n",
    "}\n",
    "\n",
    "print(\"Starting dataset preparation...\")\n",
    "\n",
    "# --- Step 1: Clean and Collect all image paths ---\n",
    "all_image_paths = []\n",
    "class_to_prefix = {}  # Map original folder name to desired prefix\n",
    "\n",
    "for src_folder_name, prefix in SOURCE_DIRS_MAP.items():\n",
    "    current_src_dir = BASE_DIR / src_folder_name\n",
    "    if not current_src_dir.exists():\n",
    "        print(f\"⚠️ Warning: Source directory '{current_src_dir}' does not exist. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"📂 Processing source directory: {current_src_dir}\")\n",
    "    for img_file in current_src_dir.iterdir():\n",
    "        if img_file.is_file():\n",
    "            if \"Copy\" in img_file.name:\n",
    "                print(f\"🗑️ Removing duplicate file: {img_file}\")\n",
    "                os.remove(img_file)\n",
    "                continue\n",
    "            all_image_paths.append((img_file, src_folder_name))\n",
    "            class_to_prefix[src_folder_name] = prefix\n",
    "\n",
    "# Exit if no images found\n",
    "if not all_image_paths:\n",
    "    print(\"🚫 No images found. Exiting.\")\n",
    "else:\n",
    "    # --- Step 2: Group by class and split ---\n",
    "    images_by_class = {cls: [] for cls in SOURCE_DIRS_MAP.keys()}\n",
    "    for img_path, cls in all_image_paths:\n",
    "        images_by_class[cls].append(img_path)\n",
    "\n",
    "    train_ratio = 0.7\n",
    "    val_ratio = 0.15\n",
    "    test_ratio = 0.15\n",
    "\n",
    "    for src_folder_name, img_list in images_by_class.items():\n",
    "        if not img_list:\n",
    "            print(f\"⚠️ No images for class '{src_folder_name}'. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n🔀 Splitting class '{src_folder_name}' ({len(img_list)} images)...\")\n",
    "\n",
    "        class_train_dir = TRAIN_DIR / src_folder_name\n",
    "        class_val_dir = VAL_DIR / src_folder_name\n",
    "        class_test_dir = TEST_DIR / src_folder_name\n",
    "        class_train_dir.mkdir(exist_ok=True, parents=True)\n",
    "        class_val_dir.mkdir(exist_ok=True, parents=True)\n",
    "        class_test_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "        train_images, temp_images = train_test_split(img_list, test_size=(val_ratio + test_ratio), random_state=42)\n",
    "        val_images, test_images = train_test_split(temp_images, test_size=(test_ratio / (val_ratio + test_ratio)), random_state=42)\n",
    "\n",
    "        print(f\"  🧪 Train: {len(train_images)} | Val: {len(val_images)} | Test: {len(test_images)}\")\n",
    "\n",
    "        def copy_and_rename(image_list, dest_dir, prefix_label):\n",
    "            for i, img_path in enumerate(image_list):\n",
    "                new_name = f\"{prefix_label}({i+1}){img_path.suffix}\"\n",
    "                shutil.copy(img_path, dest_dir / new_name)\n",
    "\n",
    "        prefix_label = class_to_prefix[src_folder_name]\n",
    "        copy_and_rename(train_images, class_train_dir, prefix_label)\n",
    "        copy_and_rename(val_images, class_val_dir, prefix_label)\n",
    "        copy_and_rename(test_images, class_test_dir, prefix_label)\n",
    "\n",
    "    # --- Final Summary ---\n",
    "    print(\"\\n✅ Dataset preparation complete!\")\n",
    "    print(f\"📁 Dataset base: {BASE_DIR}\")\n",
    "    print(f\"🧠 Train set: {len(list(TRAIN_DIR.rglob('*.*')))} files\")\n",
    "    print(f\"🧪 Val set: {len(list(VAL_DIR.rglob('*.*')))} files\")\n",
    "    print(f\"🧪 Test set: {len(list(TEST_DIR.rglob('*.*')))} files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "qkrHei-T0Wgp"
   },
   "outputs": [],
   "source": [
    "# 3. Enhanced Dataset with Advanced Augmentation\n",
    "class ECGImageDataset(Dataset):\n",
    "    label_map = {'HB': 0, 'MI': 1, 'Normal': 2, 'PMI': 3}\n",
    "\n",
    "    def __init__(self, root: Path, transform=None, is_training=False):\n",
    "        self.samples, self.transform, self.is_training = [], transform, is_training\n",
    "        self.class_counts = {i: 0 for i in self.label_map.values()}\n",
    "\n",
    "        for cls, idx in self.label_map.items():\n",
    "            pattern = rf'{cls}\\(\\d+\\)'\n",
    "            for p in root.rglob('*.jpg'):\n",
    "                if re.search(pattern, p.name):\n",
    "                    self.samples.append((p, idx))\n",
    "                    self.class_counts[idx] += 1\n",
    "\n",
    "        random.shuffle(self.samples)\n",
    "        print(f\"Dataset loaded: {len(self.samples)} samples\")\n",
    "        print(f\"Class distribution: {self.class_counts}\")\n",
    "\n",
    "    def get_class_weights(self):\n",
    "        \"\"\"Calculate class weights for balanced training\"\"\"\n",
    "        total = sum(self.class_counts.values())\n",
    "        weights = [total / (len(self.class_counts) * count) for count in self.class_counts.values()]\n",
    "        return torch.FloatTensor(weights)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.samples[idx]\n",
    "        try:\n",
    "            # Load image\n",
    "            img = Image.open(path).convert('RGB')\n",
    "            img_array = np.array(img)\n",
    "\n",
    "            # Apply transforms\n",
    "            if self.transform:\n",
    "                if isinstance(self.transform, A.Compose):\n",
    "                    # Albumentations\n",
    "                    transformed = self.transform(image=img_array)\n",
    "                    img_tensor = transformed['image']\n",
    "                else:\n",
    "                    # PyTorch transforms\n",
    "                    img_tensor = self.transform(img)\n",
    "            else:\n",
    "                img_tensor = transforms.ToTensor()(img)\n",
    "\n",
    "            return img_tensor, label, str(path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {path}: {e}\")\n",
    "\n",
    "            dummy_img = torch.zeros(3, 384, 384)\n",
    "            return dummy_img, label, str(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "x7eDWA9_0ZoJ"
   },
   "outputs": [],
   "source": [
    "# 4. Advanced Data Augmentation Pipeline\n",
    "def get_training_transforms():\n",
    "    \"\"\"Comprehensive augmentation for ECG images\"\"\"\n",
    "    return A.Compose([\n",
    "        # Geometric transforms\n",
    "        A.Resize(384, 384),\n",
    "        A.HorizontalFlip(p=0.3),  # ECG can be flipped in some cases\n",
    "        A.Rotate(limit=3, p=0.3),  # Small rotations for scanning artifacts\n",
    "        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=2, p=0.3),\n",
    "\n",
    "        # Noise and artifacts (common in ECG)\n",
    "        A.GaussNoise(var_limit=(5.0, 15.0), p=0.2),\n",
    "        A.ISONoise(color_shift=(0.01, 0.02), intensity=(0.1, 0.3), p=0.2),\n",
    "        A.MultiplicativeNoise(multiplier=(0.95, 1.05), p=0.2),\n",
    "\n",
    "        # Brightness/Contrast (for different recording conditions)\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.3),\n",
    "        A.RandomGamma(gamma_limit=(90, 110), p=0.2),\n",
    "\n",
    "        # Grid artifacts (common in ECG paper)\n",
    "        A.GridDistortion(num_steps=3, distort_limit=0.05, p=0.15),\n",
    "\n",
    "        # Normalize and convert to tensor\n",
    "        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "def get_validation_transforms():\n",
    "    \"\"\"Simple transforms for validation/test\"\"\"\n",
    "    return A.Compose([\n",
    "        A.Resize(384, 384),\n",
    "        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "        ToTensorV2()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d8qkrGXJ0dya",
    "outputId": "e27c7034-2303-4015-e38e-447281748c62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 1145 samples\n",
      "Class distribution: {0: 237, 1: 430, 2: 298, 3: 180}\n",
      "Dataset loaded: 247 samples\n",
      "Class distribution: {0: 51, 1: 93, 2: 64, 3: 39}\n"
     ]
    }
   ],
   "source": [
    "# 5. Create datasets with enhanced transforms\n",
    "train_ds = ECGImageDataset(TRAIN_DIR, transform=get_training_transforms(), is_training=True)\n",
    "val_ds = ECGImageDataset(VAL_DIR, transform=get_validation_transforms(), is_training=False)\n",
    "test_paths = sorted(TEST_DIR.glob('*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TOB_4tLp0sDF",
    "outputId": "07ba142d-4008-43e6-f9d5-61e57c503dcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: tensor([1.2078, 0.6657, 0.9606, 1.5903])\n",
      "Training batches: 36, Validation batches: 8\n"
     ]
    }
   ],
   "source": [
    "# 6. Weighted Sampling for Class Balance\n",
    "class_weights = train_ds.get_class_weights()\n",
    "sample_weights = [class_weights[label] for _, label in train_ds.samples]\n",
    "sampler = WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)\n",
    "\n",
    "# Data loaders with optimal settings\n",
    "train_loader = DataLoader(train_ds, batch_size=32, sampler=sampler, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "print(f\"Class weights: {class_weights}\")\n",
    "print(f\"Training batches: {len(train_loader)}, Validation batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "37lX_xJH0v-q"
   },
   "outputs": [],
   "source": [
    "# 7. Enhanced Model with Better Architecture - Using EfficientNetV2-S\n",
    "class ECGClassifier(nn.Module):\n",
    "    def __init__(self, model_name='tf_efficientnetv2_s', num_classes=4, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(model_name, pretrained=True, num_classes=0)\n",
    "        self.feature_dim = self.backbone.num_features\n",
    "\n",
    "        # Enhanced classifier head - Reduced size for smaller model\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(self.feature_dim, 256),  # Reduced from 512 to 256\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout/2),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "        # Initialize weights\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.classifier:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        return self.classifier(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y7NwmEMP1ApC",
    "outputId": "3a8f9afc-2c04-46ea-ac1b-f5e491fc306f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69bfce7b3496473098f93cf18328df0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/86.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 20,506,452\n",
      "Trainable parameters: 20,506,452\n",
      "Mixed precision training: Disabled\n"
     ]
    }
   ],
   "source": [
    "# 8. Training Setup with Advanced Components\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = ECGClassifier(num_classes=4).to(device)\n",
    "\n",
    "# Print model info\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "# Advanced loss function with class weighting\n",
    "# Assuming class_weights is defined elsewhere - if not, we'll compute it\n",
    "try:\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights.to(device), label_smoothing=0.1)\n",
    "except NameError:\n",
    "    print(\"Warning: class_weights not found, using unweighted loss\")\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "# Optimizer with better settings - Slightly reduced learning rate for smaller model\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=8e-4,  # Reduced from 1e-3\n",
    "    weight_decay=0.01,\n",
    "    betas=(0.9, 0.999)\n",
    ")\n",
    "\n",
    "# Advanced learning rate scheduler\n",
    "# Assuming train_loader is defined - if not, we'll use a placeholder\n",
    "try:\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=8e-4,  # Reduced from 1e-3\n",
    "        epochs=40,\n",
    "        steps_per_epoch=len(train_loader),\n",
    "        pct_start=0.1,\n",
    "        anneal_strategy='cos'\n",
    "    )\n",
    "except NameError:\n",
    "    print(\"Warning: train_loader not found, using step scheduler\")\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "# Mixed precision training - Fixed version\n",
    "use_amp = device.type == 'cuda'\n",
    "scaler = torch.cuda.amp.GradScaler() if use_amp else None\n",
    "print(f\"Mixed precision training: {'Enabled' if use_amp else 'Disabled'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TEHkG1431EZp"
   },
   "outputs": [],
   "source": [
    "# Updated Training Functions to accept parameters\n",
    "def train_epoch(model, loader, optimizer, scheduler, scaler, criterion, epoch, use_amp=True):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    \n",
    "    for batch_idx, (imgs, labels, _) in enumerate(loader):\n",
    "        imgs, labels = imgs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Mixed precision forward pass\n",
    "        if use_amp and scaler is not None:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Update scheduler if it's OneCycleLR\n",
    "        if hasattr(scheduler, 'step_update'):\n",
    "            scheduler.step()\n",
    "        elif isinstance(scheduler, torch.optim.lr_scheduler.OneCycleLR):\n",
    "            scheduler.step()\n",
    "        \n",
    "        # Statistics - ensure float32 for loss computation\n",
    "        total_loss += loss.item() * imgs.size(0)\n",
    "        predicted = outputs.argmax(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        # Progress logging\n",
    "        if batch_idx % 50 == 0:\n",
    "            lr = optimizer.param_groups[0]['lr']\n",
    "            print(f'Epoch {epoch} [{batch_idx}/{len(loader)}] '\n",
    "                  f'Loss: {loss.item():.4f} Acc: {100.*correct/total:.2f}% LR: {lr:.6f}')\n",
    "    \n",
    "    return total_loss/total, correct/total\n",
    "\n",
    "def validate_epoch(model, loader, criterion, use_amp=True):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    all_preds, all_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for imgs, labels, _ in loader:\n",
    "            imgs, labels = imgs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "            \n",
    "            # Proper mixed precision validation\n",
    "            if use_amp:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    outputs = model(imgs)\n",
    "                    # Convert to float32 for loss computation\n",
    "                    loss = criterion(outputs.float(), labels)\n",
    "            else:\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item() * imgs.size(0)\n",
    "            predicted = outputs.argmax(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    return total_loss/total, correct/total, all_preds, all_labels\n",
    "\n",
    "# Fixed Training Function - accepts model and model_name as parameters\n",
    "def train_model(model, train_loader, val_loader, optimizer, scheduler, scaler, criterion, model_name, epochs=40, patience=8, use_amp=True):\n",
    "    best_acc = 0\n",
    "    no_improve = 0\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accs, val_accs = [], []\n",
    "    \n",
    "    print(f\"Starting training for {model_name}...\")\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        try:\n",
    "            # Training\n",
    "            train_loss, train_acc = train_epoch(model, train_loader, optimizer, scheduler, scaler, criterion, epoch, use_amp)\n",
    "            \n",
    "            # Validation\n",
    "            val_loss, val_acc, val_preds, val_labels = validate_epoch(model, val_loader, criterion, use_amp)\n",
    "            \n",
    "            # Save metrics\n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "            train_accs.append(train_acc)\n",
    "            val_accs.append(val_acc)\n",
    "            \n",
    "            print(f\"\\nEpoch {epoch}/{epochs}\")\n",
    "            print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "            print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            # Save best model\n",
    "            if val_acc > best_acc:\n",
    "                best_acc = val_acc\n",
    "                no_improve = 0\n",
    "                \n",
    "                # Create models directory if it doesn't exist\n",
    "                models_dir = MODELS_DIR\n",
    "                models_dir.mkdir(exist_ok=True)\n",
    "                \n",
    "                # Save with model-specific filename\n",
    "                checkpoint_name = f'best_{model_name.replace(\"/\", \"_\")}_model.pth'\n",
    "                \n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'scheduler_state_dict': scheduler.state_dict(),\n",
    "                    'best_acc': best_acc,\n",
    "                    'train_losses': train_losses,\n",
    "                    'val_losses': val_losses,\n",
    "                    'train_accs': train_accs,\n",
    "                    'val_accs': val_accs,\n",
    "                    'model_config': {\n",
    "                        'num_classes': 4,\n",
    "                        'model_name': model_name  # Now uses actual model name\n",
    "                    }\n",
    "                }, models_dir / checkpoint_name)\n",
    "                \n",
    "                print(f\"✅ New best model saved! Validation Accuracy: {best_acc:.4f}\")\n",
    "            else:\n",
    "                no_improve += 1\n",
    "            \n",
    "            # Update scheduler if it's not OneCycleLR\n",
    "            if not isinstance(scheduler, torch.optim.lr_scheduler.OneCycleLR):\n",
    "                scheduler.step()\n",
    "            \n",
    "            # Early stopping\n",
    "            if no_improve >= patience:\n",
    "                print(f\"Early stopping after {epoch} epochs\")\n",
    "                break\n",
    "                \n",
    "            # Memory cleanup - More frequent for smaller GPU memory\n",
    "            if epoch % 3 == 0:\n",
    "                gc.collect()\n",
    "                if device.type == 'cuda':\n",
    "                    torch.cuda.empty_cache()\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error in epoch {epoch}: {str(e)}\")\n",
    "            print(\"Continuing to next epoch...\")\n",
    "            continue\n",
    "    \n",
    "    return {\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'train_accs': train_accs,\n",
    "        'val_accs': val_accs,\n",
    "        'best_acc': best_acc,\n",
    "        'model_name': model_name\n",
    "    }\n",
    "\n",
    "# Fixed Model Comparison Loop\n",
    "model_names = [\n",
    "    'efficientnet_b0',\n",
    "    'tf_efficientnetv2_s',\n",
    "    'resnext50_32x4d',\n",
    "]\n",
    "\n",
    "comparison_results = {}\n",
    "\n",
    "for model_name in model_names:\n",
    "    print(f\"\\n🔁 Training with model: {model_name}\")\n",
    "    \n",
    "    try:\n",
    "        # Clear GPU memory before each model\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        # Reinitialize model and move to device\n",
    "        model = ECGClassifier(model_name=model_name, num_classes=4).to(device)\n",
    "        \n",
    "        # Print model info\n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        print(f\"Model parameters: {total_params:,}\")\n",
    "        \n",
    "        # Redefine optimizer and scheduler for each model\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=8e-4,\n",
    "            weight_decay=0.01,\n",
    "            betas=(0.9, 0.999)\n",
    "        )\n",
    "        \n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            optimizer,\n",
    "            max_lr=8e-4,\n",
    "            epochs=40,\n",
    "            steps_per_epoch=len(train_loader),\n",
    "            pct_start=0.1,\n",
    "            anneal_strategy='cos'\n",
    "        )\n",
    "        \n",
    "        # Redefine scaler for mixed precision\n",
    "        scaler = torch.cuda.amp.GradScaler() if use_amp else None\n",
    "        \n",
    "        # Define criterion for each model\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Train the model with all required parameters\n",
    "        result = train_model(\n",
    "            model=model,\n",
    "            train_loader=train_loader, \n",
    "            val_loader=val_loader,\n",
    "            optimizer=optimizer,\n",
    "            scheduler=scheduler,\n",
    "            scaler=scaler,\n",
    "            criterion=criterion,\n",
    "            model_name=model_name,\n",
    "            epochs=40, \n",
    "            patience=8,\n",
    "            use_amp=use_amp\n",
    "        )\n",
    "        \n",
    "        # Store results for comparison\n",
    "        comparison_results[model_name] = {\n",
    "            'best_acc': result['best_acc'],\n",
    "            'total_params': total_params,\n",
    "            'final_epoch': len(result['train_losses'])\n",
    "        }\n",
    "        \n",
    "        print(f\"✅ Finished {model_name}\")\n",
    "        print(f\"   Best Val Accuracy: {result['best_acc']:.4f}\")\n",
    "        print(f\"   Total Parameters: {total_params:,}\")\n",
    "        print(f\"   Training Epochs: {len(result['train_losses'])}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        # Force cleanup between models\n",
    "        del model, optimizer, scheduler, scaler\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error training {model_name}: {str(e)}\")\n",
    "        comparison_results[model_name] = {'best_acc': 0.0, 'error': str(e)}\n",
    "        continue\n",
    "\n",
    "# Summary of all model performances\n",
    "print(\"\\n📊 Model Performance Summary:\")\n",
    "print(\"=\" * 70)\n",
    "for name, results in comparison_results.items():\n",
    "    if 'error' in results:\n",
    "        print(f\"{name:20s}: ERROR - {results['error']}\")\n",
    "    else:\n",
    "        print(f\"{name:20s}: {results['best_acc']:.4f} acc | {results['total_params']:,} params | {results['final_epoch']} epochs\")\n",
    "\n",
    "# Find best model\n",
    "if comparison_results:\n",
    "    best_model = max(comparison_results.items(), \n",
    "                    key=lambda x: x[1].get('best_acc', 0))\n",
    "    print(f\"\\n🏆 Best Model: {best_model[0]} with {best_model[1]['best_acc']:.4f} accuracy\")\n",
    "\n",
    "# Memory monitoring function for Colab\n",
    "def check_gpu_memory():\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1024**3  # Convert to GB\n",
    "        reserved = torch.cuda.memory_reserved() / 1024**3\n",
    "        print(f\"GPU Memory - Allocated: {allocated:.2f}GB, Reserved: {reserved:.2f}GB\")\n",
    "        return allocated, reserved\n",
    "    return 0, 0\n",
    "\n",
    "# Check final memory usage\n",
    "check_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pr_LmkTy1IKE",
    "outputId": "c5239f4e-3854-4c20-f5d8-0e2eafe64d6f"
   },
   "outputs": [],
   "source": [
    "# 10. Enhanced Training Loop with Early Stopping\n",
    "def train_model(train_loader, val_loader, epochs=40, patience=8):\n",
    "    best_acc = 0\n",
    "    no_improve = 0\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accs, val_accs = [], []\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        try:\n",
    "            # Training\n",
    "            train_loss, train_acc = train_epoch(train_loader, epoch)\n",
    "\n",
    "            # Validation\n",
    "            val_loss, val_acc, val_preds, val_labels = validate_epoch(val_loader)\n",
    "\n",
    "            # Save metrics\n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "            train_accs.append(train_acc)\n",
    "            val_accs.append(val_acc)\n",
    "\n",
    "            print(f\"\\nEpoch {epoch}/{epochs}\")\n",
    "            print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "            print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "            # Save best model\n",
    "            if val_acc > best_acc:\n",
    "                best_acc = val_acc\n",
    "                no_improve = 0\n",
    "\n",
    "                # Create models directory if it doesn't exist\n",
    "                models_dir = MODELS_DIR\n",
    "                models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'scheduler_state_dict': scheduler.state_dict(),\n",
    "                    'best_acc': best_acc,\n",
    "                    'train_losses': train_losses,\n",
    "                    'val_losses': val_losses,\n",
    "                    'train_accs': train_accs,\n",
    "                    'val_accs': val_accs,\n",
    "                    'model_config': {\n",
    "                        'num_classes': 4,\n",
    "                        'model_name': 'tf_efficientnetv2_s'  # Updated model name\n",
    "                    }\n",
    "                }, models_dir / 'best_ecg_model.pth')\n",
    "                print(f\"✅ New best model saved! Validation Accuracy: {best_acc:.4f}\")\n",
    "            else:\n",
    "                no_improve += 1\n",
    "\n",
    "            # Update scheduler if it's not OneCycleLR\n",
    "            if not isinstance(scheduler, torch.optim.lr_scheduler.OneCycleLR):\n",
    "                scheduler.step()\n",
    "\n",
    "            # Early stopping\n",
    "            if no_improve >= patience:\n",
    "                print(f\"Early stopping after {epoch} epochs\")\n",
    "                break\n",
    "\n",
    "            # Memory cleanup - More frequent for smaller GPU memory\n",
    "            if epoch % 3 == 0:  # Changed from 5 to 3\n",
    "                gc.collect()\n",
    "                if device.type == 'cuda':\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in epoch {epoch}: {str(e)}\")\n",
    "            print(\"Continuing to next epoch...\")\n",
    "            continue\n",
    "\n",
    "    return {\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'train_accs': train_accs,\n",
    "        'val_accs': val_accs,\n",
    "        'best_acc': best_acc\n",
    "    }\n",
    "\n",
    "# Memory monitoring function for Colab\n",
    "def check_gpu_memory():\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1024**3  # Convert to GB\n",
    "        reserved = torch.cuda.memory_reserved() / 1024**3\n",
    "        print(f\"GPU Memory - Allocated: {allocated:.2f}GB, Reserved: {reserved:.2f}GB\")\n",
    "        return allocated, reserved\n",
    "    return 0, 0\n",
    "\n",
    "# Example usage:\n",
    "check_gpu_memory()  # Check initial memory usage\n",
    "results = train_model(train_loader, val_loader, epochs=40, patience=8)\n",
    "\n",
    "print(\"✅ Training setup complete with EfficientNetV2-S!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "33e05f1233f34951aae9d04a9550e0d8",
      "1e1e43b734c044d494b119dbf8db2c29",
      "4d8a77048d6b4b14be4bda8f5d52357a",
      "6446fa70ea2f4960a5fedcca206f4a80",
      "939170c5f5a94559b9b409b43ff11619",
      "edebf3fad31e41e1ace8a7168ea06582",
      "8e488f9a3f694e9c84114576293c5c65",
      "1fbf668f1bc44a41ab4909c625281486",
      "b9b61a45a36041c0ace462f0be78cf7c",
      "637e60293ba44f15a5b2c1af0b2073c4",
      "c916e0d7ca42472abfa7f53f20754ad0",
      "e5d3ebcfc36e4fcc9fd6d336905c7b68",
      "691c18d74a974823a187dd82c6942f2a",
      "6becdea84fce4e50b202393c4f127511",
      "242617d20f3e47f485335eeb80b3d65c",
      "41ab583f11604f7582539116c500d4c0",
      "32bbbed09ced4246bf41c6f3f4460c70",
      "5c7698a44af54eaf9ba87077fabcaee2",
      "485d839fde4e409b81c7036769eab8b4",
      "8527ca023b3c49a18c1d6015b9416ed5",
      "7664301a89e143aa86d981e2c66a1b89",
      "e0a28c0e5e504a71a7d7d0b99e8851ad"
     ]
    },
    "id": "uO6XUChL-5ZF",
    "outputId": "3fa7ca15-9a6c-4904-aead-1ccebbe1c66f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 Training with model: tf_efficientnetv2_s\n",
      "Starting training...\n",
      "Epoch 1 [0/36] Loss: 1.6513 Acc: 28.12% LR: 0.000032\n",
      "\n",
      "Epoch 1/40\n",
      "Train Loss: 1.3873 | Train Acc: 0.3572\n",
      "Val Loss: 1.1001 | Val Acc: 0.5344\n",
      "--------------------------------------------------\n",
      "✅ New best model saved! Validation Accuracy: 0.5344\n",
      "Epoch 2 [0/36] Loss: 1.0868 Acc: 62.50% LR: 0.000152\n",
      "\n",
      "Epoch 2/40\n",
      "Train Loss: 1.0102 | Train Acc: 0.5904\n",
      "Val Loss: 0.8211 | Val Acc: 0.7490\n",
      "--------------------------------------------------\n",
      "✅ New best model saved! Validation Accuracy: 0.7490\n",
      "Epoch 3 [0/36] Loss: 0.9051 Acc: 62.50% LR: 0.000429\n",
      "\n",
      "Epoch 3/40\n",
      "Train Loss: 0.7684 | Train Acc: 0.7450\n",
      "Val Loss: 0.7146 | Val Acc: 0.7935\n",
      "--------------------------------------------------\n",
      "✅ New best model saved! Validation Accuracy: 0.7935\n",
      "Epoch 4 [0/36] Loss: 0.6507 Acc: 81.25% LR: 0.000698\n",
      "\n",
      "Epoch 4/40\n",
      "Train Loss: 0.6840 | Train Acc: 0.8096\n",
      "Val Loss: 0.8009 | Val Acc: 0.7814\n",
      "--------------------------------------------------\n",
      "Epoch 5 [0/36] Loss: 0.6041 Acc: 84.38% LR: 0.000800\n",
      "\n",
      "Epoch 5/40\n",
      "Train Loss: 0.6623 | Train Acc: 0.8227\n",
      "Val Loss: 0.6153 | Val Acc: 0.8381\n",
      "--------------------------------------------------\n",
      "✅ New best model saved! Validation Accuracy: 0.8381\n",
      "Epoch 6 [0/36] Loss: 0.6536 Acc: 78.12% LR: 0.000798\n",
      "\n",
      "Epoch 6/40\n",
      "Train Loss: 0.6090 | Train Acc: 0.8306\n",
      "Val Loss: 0.7080 | Val Acc: 0.7854\n",
      "--------------------------------------------------\n",
      "Epoch 7 [0/36] Loss: 0.5693 Acc: 90.62% LR: 0.000794\n",
      "\n",
      "Epoch 7/40\n",
      "Train Loss: 0.5902 | Train Acc: 0.8524\n",
      "Val Loss: 0.6323 | Val Acc: 0.8300\n",
      "--------------------------------------------------\n",
      "Epoch 8 [0/36] Loss: 0.5755 Acc: 84.38% LR: 0.000786\n",
      "\n",
      "Epoch 8/40\n",
      "Train Loss: 0.5729 | Train Acc: 0.8568\n",
      "Val Loss: 0.6067 | Val Acc: 0.8259\n",
      "--------------------------------------------------\n",
      "Epoch 9 [0/36] Loss: 0.5896 Acc: 90.62% LR: 0.000775\n",
      "\n",
      "Epoch 9/40\n",
      "Train Loss: 0.5295 | Train Acc: 0.8742\n",
      "Val Loss: 0.5757 | Val Acc: 0.8381\n",
      "--------------------------------------------------\n",
      "Epoch 10 [0/36] Loss: 0.5572 Acc: 84.38% LR: 0.000762\n",
      "\n",
      "Epoch 10/40\n",
      "Train Loss: 0.5643 | Train Acc: 0.8472\n",
      "Val Loss: 0.6066 | Val Acc: 0.8421\n",
      "--------------------------------------------------\n",
      "✅ New best model saved! Validation Accuracy: 0.8421\n",
      "Epoch 11 [0/36] Loss: 0.4811 Acc: 90.62% LR: 0.000745\n",
      "\n",
      "Epoch 11/40\n",
      "Train Loss: 0.5583 | Train Acc: 0.8603\n",
      "Val Loss: 0.5897 | Val Acc: 0.8259\n",
      "--------------------------------------------------\n",
      "Epoch 12 [0/36] Loss: 0.5220 Acc: 93.75% LR: 0.000727\n",
      "\n",
      "Epoch 12/40\n",
      "Train Loss: 0.5572 | Train Acc: 0.8620\n",
      "Val Loss: 0.5769 | Val Acc: 0.8340\n",
      "--------------------------------------------------\n",
      "Epoch 13 [0/36] Loss: 0.5319 Acc: 87.50% LR: 0.000705\n",
      "\n",
      "Epoch 13/40\n",
      "Train Loss: 0.5317 | Train Acc: 0.8751\n",
      "Val Loss: 0.5826 | Val Acc: 0.8421\n",
      "--------------------------------------------------\n",
      "Epoch 14 [0/36] Loss: 0.6093 Acc: 84.38% LR: 0.000681\n",
      "\n",
      "Epoch 14/40\n",
      "Train Loss: 0.5120 | Train Acc: 0.8812\n",
      "Val Loss: 0.6404 | Val Acc: 0.8300\n",
      "--------------------------------------------------\n",
      "Epoch 15 [0/36] Loss: 0.4447 Acc: 93.75% LR: 0.000656\n",
      "\n",
      "Epoch 15/40\n",
      "Train Loss: 0.5250 | Train Acc: 0.8760\n",
      "Val Loss: 0.5950 | Val Acc: 0.8381\n",
      "--------------------------------------------------\n",
      "Epoch 16 [0/36] Loss: 0.4455 Acc: 93.75% LR: 0.000628\n",
      "\n",
      "Epoch 16/40\n",
      "Train Loss: 0.4911 | Train Acc: 0.9057\n",
      "Val Loss: 0.5890 | Val Acc: 0.8340\n",
      "--------------------------------------------------\n",
      "Epoch 17 [0/36] Loss: 0.5020 Acc: 87.50% LR: 0.000598\n",
      "\n",
      "Epoch 17/40\n",
      "Train Loss: 0.5042 | Train Acc: 0.8865\n",
      "Val Loss: 0.5974 | Val Acc: 0.8300\n",
      "--------------------------------------------------\n",
      "Epoch 18 [0/36] Loss: 0.5093 Acc: 87.50% LR: 0.000567\n",
      "\n",
      "Epoch 18/40\n",
      "Train Loss: 0.5374 | Train Acc: 0.8699\n",
      "Val Loss: 0.5839 | Val Acc: 0.8381\n",
      "--------------------------------------------------\n",
      "Early stopping after 18 epochs\n",
      "✅ Finished tf_efficientnetv2_s | Best Val Accuracy: 0.8421\n",
      "------------------------------------------------------------\n",
      "\n",
      "🔁 Training with model: tf_efficientnetv2_m\n",
      "Starting training...\n",
      "Epoch 1 [0/36] Loss: 1.5757 Acc: 25.00% LR: 0.000032\n",
      "\n",
      "Epoch 1/40\n",
      "Train Loss: 1.3636 | Train Acc: 0.3869\n",
      "Val Loss: 1.1138 | Val Acc: 0.4737\n",
      "--------------------------------------------------\n",
      "✅ New best model saved! Validation Accuracy: 0.4737\n",
      "Epoch 2 [0/36] Loss: 1.3121 Acc: 34.38% LR: 0.000152\n",
      "\n",
      "Epoch 2/40\n",
      "Train Loss: 0.9932 | Train Acc: 0.6114\n",
      "Val Loss: 0.9087 | Val Acc: 0.6761\n",
      "--------------------------------------------------\n",
      "✅ New best model saved! Validation Accuracy: 0.6761\n",
      "Epoch 3 [0/36] Loss: 0.8899 Acc: 62.50% LR: 0.000429\n",
      "\n",
      "Epoch 3/40\n",
      "Train Loss: 0.8013 | Train Acc: 0.7275\n",
      "Val Loss: 0.7215 | Val Acc: 0.7854\n",
      "--------------------------------------------------\n",
      "✅ New best model saved! Validation Accuracy: 0.7854\n",
      "Epoch 4 [0/36] Loss: 0.8063 Acc: 71.88% LR: 0.000698\n",
      "\n",
      "Epoch 4/40\n",
      "Train Loss: 0.6779 | Train Acc: 0.8061\n",
      "Val Loss: 0.6570 | Val Acc: 0.7733\n",
      "--------------------------------------------------\n",
      "Epoch 5 [0/36] Loss: 0.5479 Acc: 84.38% LR: 0.000800\n",
      "\n",
      "Epoch 5/40\n",
      "Train Loss: 0.6335 | Train Acc: 0.8314\n",
      "Val Loss: 0.6709 | Val Acc: 0.8178\n",
      "--------------------------------------------------\n",
      "✅ New best model saved! Validation Accuracy: 0.8178\n",
      "Epoch 6 [0/36] Loss: 0.5990 Acc: 81.25% LR: 0.000798\n",
      "\n",
      "Epoch 6/40\n",
      "Train Loss: 0.5981 | Train Acc: 0.8437\n",
      "Val Loss: 0.6116 | Val Acc: 0.8259\n",
      "--------------------------------------------------\n",
      "✅ New best model saved! Validation Accuracy: 0.8259\n",
      "Epoch 7 [0/36] Loss: 0.5361 Acc: 90.62% LR: 0.000794\n",
      "\n",
      "Epoch 7/40\n",
      "Train Loss: 0.5638 | Train Acc: 0.8699\n",
      "Val Loss: 0.6073 | Val Acc: 0.8340\n",
      "--------------------------------------------------\n",
      "✅ New best model saved! Validation Accuracy: 0.8340\n",
      "Epoch 8 [0/36] Loss: 0.4588 Acc: 96.88% LR: 0.000786\n",
      "\n",
      "Epoch 8/40\n",
      "Train Loss: 0.5331 | Train Acc: 0.8830\n",
      "Val Loss: 0.6096 | Val Acc: 0.8259\n",
      "--------------------------------------------------\n",
      "Epoch 9 [0/36] Loss: 0.4164 Acc: 96.88% LR: 0.000775\n",
      "\n",
      "Epoch 9/40\n",
      "Train Loss: 0.5288 | Train Acc: 0.8856\n",
      "Val Loss: 0.6051 | Val Acc: 0.8300\n",
      "--------------------------------------------------\n",
      "Epoch 10 [0/36] Loss: 0.5397 Acc: 81.25% LR: 0.000762\n",
      "\n",
      "Epoch 10/40\n",
      "Train Loss: 0.5235 | Train Acc: 0.8891\n",
      "Val Loss: 0.5720 | Val Acc: 0.8381\n",
      "--------------------------------------------------\n",
      "✅ New best model saved! Validation Accuracy: 0.8381\n",
      "Epoch 11 [0/36] Loss: 0.5139 Acc: 90.62% LR: 0.000745\n",
      "\n",
      "Epoch 11/40\n",
      "Train Loss: 0.5345 | Train Acc: 0.8690\n",
      "Val Loss: 0.5915 | Val Acc: 0.8381\n",
      "--------------------------------------------------\n",
      "Epoch 12 [0/36] Loss: 0.5893 Acc: 84.38% LR: 0.000727\n",
      "\n",
      "Epoch 12/40\n",
      "Train Loss: 0.5075 | Train Acc: 0.8873\n",
      "Val Loss: 0.5859 | Val Acc: 0.8300\n",
      "--------------------------------------------------\n",
      "Epoch 13 [0/36] Loss: 0.6002 Acc: 81.25% LR: 0.000705\n",
      "\n",
      "Epoch 13/40\n",
      "Train Loss: 0.5173 | Train Acc: 0.8908\n",
      "Val Loss: 0.6398 | Val Acc: 0.8219\n",
      "--------------------------------------------------\n",
      "Epoch 14 [0/36] Loss: 0.6547 Acc: 78.12% LR: 0.000681\n",
      "\n",
      "Epoch 14/40\n",
      "Train Loss: 0.5240 | Train Acc: 0.8847\n",
      "Val Loss: 0.5992 | Val Acc: 0.8340\n",
      "--------------------------------------------------\n",
      "Epoch 15 [0/36] Loss: 0.5302 Acc: 84.38% LR: 0.000656\n",
      "\n",
      "Epoch 15/40\n",
      "Train Loss: 0.5091 | Train Acc: 0.8812\n",
      "Val Loss: 0.5710 | Val Acc: 0.8381\n",
      "--------------------------------------------------\n",
      "Epoch 16 [0/36] Loss: 0.4492 Acc: 93.75% LR: 0.000628\n",
      "\n",
      "Epoch 16/40\n",
      "Train Loss: 0.5055 | Train Acc: 0.8821\n",
      "Val Loss: 0.5922 | Val Acc: 0.8381\n",
      "--------------------------------------------------\n",
      "Epoch 17 [0/36] Loss: 0.4719 Acc: 90.62% LR: 0.000598\n",
      "\n",
      "Epoch 17/40\n",
      "Train Loss: 0.4883 | Train Acc: 0.8926\n",
      "Val Loss: 0.6081 | Val Acc: 0.8381\n",
      "--------------------------------------------------\n",
      "Epoch 18 [0/36] Loss: 0.4090 Acc: 96.88% LR: 0.000567\n",
      "\n",
      "Epoch 18/40\n",
      "Train Loss: 0.5199 | Train Acc: 0.8769\n",
      "Val Loss: 0.5851 | Val Acc: 0.8340\n",
      "--------------------------------------------------\n",
      "Early stopping after 18 epochs\n",
      "✅ Finished tf_efficientnetv2_m | Best Val Accuracy: 0.8381\n",
      "------------------------------------------------------------\n",
      "\n",
      "🔁 Training with model: convnext_tiny\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33e05f1233f34951aae9d04a9550e0d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/114M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 1 [0/36] Loss: 2.5545 Acc: 28.12% LR: 0.000032\n",
      "\n",
      "Epoch 1/40\n",
      "Train Loss: 1.8067 | Train Acc: 0.2376\n",
      "Val Loss: 1.4515 | Val Acc: 0.2065\n",
      "--------------------------------------------------\n",
      "✅ New best model saved! Validation Accuracy: 0.2065\n",
      "Epoch 2 [0/36] Loss: 1.3326 Acc: 28.12% LR: 0.000152\n",
      "\n",
      "Epoch 2/40\n",
      "Train Loss: 1.3910 | Train Acc: 0.2786\n",
      "Val Loss: 1.4830 | Val Acc: 0.1579\n",
      "--------------------------------------------------\n",
      "Epoch 3 [0/36] Loss: 1.3722 Acc: 21.88% LR: 0.000429\n",
      "\n",
      "Epoch 3/40\n",
      "Train Loss: 1.3779 | Train Acc: 0.2559\n",
      "Val Loss: 1.4671 | Val Acc: 0.2065\n",
      "--------------------------------------------------\n",
      "Epoch 4 [0/36] Loss: 1.4198 Acc: 25.00% LR: 0.000698\n",
      "\n",
      "Epoch 4/40\n",
      "Train Loss: 1.3584 | Train Acc: 0.2699\n",
      "Val Loss: 1.4127 | Val Acc: 0.1579\n",
      "--------------------------------------------------\n",
      "Epoch 5 [0/36] Loss: 1.3919 Acc: 15.62% LR: 0.000800\n",
      "\n",
      "Epoch 5/40\n",
      "Train Loss: 1.3871 | Train Acc: 0.2192\n",
      "Val Loss: 1.4313 | Val Acc: 0.1579\n",
      "--------------------------------------------------\n",
      "Epoch 6 [0/36] Loss: 1.2470 Acc: 34.38% LR: 0.000798\n",
      "\n",
      "Epoch 6/40\n",
      "Train Loss: 1.3697 | Train Acc: 0.2323\n",
      "Val Loss: 1.4277 | Val Acc: 0.1579\n",
      "--------------------------------------------------\n",
      "Epoch 7 [0/36] Loss: 1.3057 Acc: 37.50% LR: 0.000794\n",
      "\n",
      "Epoch 7/40\n",
      "Train Loss: 1.3540 | Train Acc: 0.2463\n",
      "Val Loss: 1.4470 | Val Acc: 0.1579\n",
      "--------------------------------------------------\n",
      "Epoch 8 [0/36] Loss: 1.3704 Acc: 18.75% LR: 0.000786\n",
      "\n",
      "Epoch 8/40\n",
      "Train Loss: 1.3620 | Train Acc: 0.2376\n",
      "Val Loss: 1.4207 | Val Acc: 0.1579\n",
      "--------------------------------------------------\n",
      "Epoch 9 [0/36] Loss: 1.3379 Acc: 25.00% LR: 0.000775\n",
      "\n",
      "Epoch 9/40\n",
      "Train Loss: 1.3555 | Train Acc: 0.2419\n",
      "Val Loss: 1.4240 | Val Acc: 0.1579\n",
      "--------------------------------------------------\n",
      "Early stopping after 9 epochs\n",
      "✅ Finished convnext_tiny | Best Val Accuracy: 0.2065\n",
      "------------------------------------------------------------\n",
      "\n",
      "🔁 Training with model: resnext50_32x4d\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5d3ebcfc36e4fcc9fd6d336905c7b68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/100M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 1 [0/36] Loss: 1.3745 Acc: 28.12% LR: 0.000032\n",
      "\n",
      "Epoch 1/40\n",
      "Train Loss: 1.3614 | Train Acc: 0.2760\n",
      "Val Loss: 1.3950 | Val Acc: 0.1741\n",
      "--------------------------------------------------\n",
      "✅ New best model saved! Validation Accuracy: 0.1741\n",
      "Epoch 2 [0/36] Loss: 1.3658 Acc: 28.12% LR: 0.000152\n",
      "\n",
      "Epoch 2/40\n",
      "Train Loss: 1.2143 | Train Acc: 0.3668\n",
      "Val Loss: 1.0948 | Val Acc: 0.4899\n",
      "--------------------------------------------------\n",
      "✅ New best model saved! Validation Accuracy: 0.4899\n",
      "Epoch 3 [0/36] Loss: 1.1255 Acc: 50.00% LR: 0.000429\n",
      "\n",
      "Epoch 3/40\n",
      "Train Loss: 0.8874 | Train Acc: 0.6568\n",
      "Val Loss: 0.7849 | Val Acc: 0.7287\n",
      "--------------------------------------------------\n",
      "✅ New best model saved! Validation Accuracy: 0.7287\n",
      "Epoch 4 [0/36] Loss: 0.9752 Acc: 65.62% LR: 0.000698\n",
      "\n",
      "Epoch 4/40\n",
      "Train Loss: 0.7141 | Train Acc: 0.7799\n",
      "Val Loss: 0.6964 | Val Acc: 0.7976\n",
      "--------------------------------------------------\n",
      "✅ New best model saved! Validation Accuracy: 0.7976\n",
      "Epoch 5 [0/36] Loss: 0.5534 Acc: 87.50% LR: 0.000800\n",
      "\n",
      "Epoch 5/40\n",
      "Train Loss: 0.6405 | Train Acc: 0.8166\n",
      "Val Loss: 0.6420 | Val Acc: 0.8178\n",
      "--------------------------------------------------\n",
      "✅ New best model saved! Validation Accuracy: 0.8178\n",
      "Epoch 6 [0/36] Loss: 0.5393 Acc: 90.62% LR: 0.000798\n",
      "\n",
      "Epoch 6/40\n",
      "Train Loss: 0.5893 | Train Acc: 0.8507\n",
      "Val Loss: 0.6663 | Val Acc: 0.8057\n",
      "--------------------------------------------------\n",
      "Epoch 7 [0/36] Loss: 0.5162 Acc: 90.62% LR: 0.000794\n",
      "\n",
      "Epoch 7/40\n",
      "Train Loss: 0.5337 | Train Acc: 0.8803\n",
      "Val Loss: 0.6162 | Val Acc: 0.8178\n",
      "--------------------------------------------------\n",
      "Epoch 8 [0/36] Loss: 0.6292 Acc: 81.25% LR: 0.000786\n",
      "\n",
      "Epoch 8/40\n",
      "Train Loss: 0.5471 | Train Acc: 0.8716\n",
      "Val Loss: 0.6439 | Val Acc: 0.8057\n",
      "--------------------------------------------------\n",
      "Epoch 9 [0/36] Loss: 0.4743 Acc: 87.50% LR: 0.000775\n",
      "\n",
      "Epoch 9/40\n",
      "Train Loss: 0.5368 | Train Acc: 0.8734\n",
      "Val Loss: 0.5977 | Val Acc: 0.8097\n",
      "--------------------------------------------------\n",
      "Epoch 10 [0/36] Loss: 0.5598 Acc: 84.38% LR: 0.000762\n",
      "\n",
      "Epoch 10/40\n",
      "Train Loss: 0.5442 | Train Acc: 0.8760\n",
      "Val Loss: 0.6081 | Val Acc: 0.8138\n",
      "--------------------------------------------------\n",
      "Epoch 11 [0/36] Loss: 0.5131 Acc: 84.38% LR: 0.000745\n",
      "\n",
      "Epoch 11/40\n",
      "Train Loss: 0.5465 | Train Acc: 0.8672\n",
      "Val Loss: 0.5869 | Val Acc: 0.8340\n",
      "--------------------------------------------------\n",
      "✅ New best model saved! Validation Accuracy: 0.8340\n",
      "Epoch 12 [0/36] Loss: 0.4772 Acc: 93.75% LR: 0.000727\n",
      "\n",
      "Epoch 12/40\n",
      "Train Loss: 0.5274 | Train Acc: 0.8821\n",
      "Val Loss: 0.6272 | Val Acc: 0.8300\n",
      "--------------------------------------------------\n",
      "Epoch 13 [0/36] Loss: 0.4702 Acc: 90.62% LR: 0.000705\n",
      "\n",
      "Epoch 13/40\n",
      "Train Loss: 0.5242 | Train Acc: 0.8847\n",
      "Val Loss: 0.6154 | Val Acc: 0.8300\n",
      "--------------------------------------------------\n",
      "Epoch 14 [0/36] Loss: 0.5460 Acc: 87.50% LR: 0.000681\n",
      "\n",
      "Epoch 14/40\n",
      "Train Loss: 0.5026 | Train Acc: 0.8978\n",
      "Val Loss: 0.6149 | Val Acc: 0.8300\n",
      "--------------------------------------------------\n",
      "Epoch 15 [0/36] Loss: 0.3976 Acc: 96.88% LR: 0.000656\n",
      "\n",
      "Epoch 15/40\n",
      "Train Loss: 0.5290 | Train Acc: 0.8716\n",
      "Val Loss: 0.6103 | Val Acc: 0.8219\n",
      "--------------------------------------------------\n",
      "Epoch 16 [0/36] Loss: 0.4651 Acc: 93.75% LR: 0.000628\n",
      "\n",
      "Epoch 16/40\n",
      "Train Loss: 0.5158 | Train Acc: 0.8856\n",
      "Val Loss: 0.6058 | Val Acc: 0.8138\n",
      "--------------------------------------------------\n",
      "Epoch 17 [0/36] Loss: 0.5445 Acc: 84.38% LR: 0.000598\n",
      "\n",
      "Epoch 17/40\n",
      "Train Loss: 0.5154 | Train Acc: 0.8856\n",
      "Val Loss: 0.5902 | Val Acc: 0.8340\n",
      "--------------------------------------------------\n",
      "Epoch 18 [0/36] Loss: 0.5211 Acc: 90.62% LR: 0.000567\n",
      "\n",
      "Epoch 18/40\n",
      "Train Loss: 0.5203 | Train Acc: 0.8795\n",
      "Val Loss: 0.6998 | Val Acc: 0.8138\n",
      "--------------------------------------------------\n",
      "Epoch 19 [0/36] Loss: 0.4251 Acc: 93.75% LR: 0.000535\n",
      "\n",
      "Epoch 19/40\n",
      "Train Loss: 0.5201 | Train Acc: 0.8803\n",
      "Val Loss: 0.5769 | Val Acc: 0.8381\n",
      "--------------------------------------------------\n",
      "✅ New best model saved! Validation Accuracy: 0.8381\n",
      "Epoch 20 [0/36] Loss: 0.4879 Acc: 90.62% LR: 0.000502\n",
      "\n",
      "Epoch 20/40\n",
      "Train Loss: 0.4972 | Train Acc: 0.8943\n",
      "Val Loss: 0.5839 | Val Acc: 0.8381\n",
      "--------------------------------------------------\n",
      "Epoch 21 [0/36] Loss: 0.4378 Acc: 90.62% LR: 0.000468\n",
      "\n",
      "Epoch 21/40\n",
      "Train Loss: 0.4989 | Train Acc: 0.8961\n",
      "Val Loss: 0.5794 | Val Acc: 0.8340\n",
      "--------------------------------------------------\n",
      "Epoch 22 [0/36] Loss: 0.4612 Acc: 93.75% LR: 0.000433\n",
      "\n",
      "Epoch 22/40\n",
      "Train Loss: 0.5157 | Train Acc: 0.8707\n",
      "Val Loss: 0.5831 | Val Acc: 0.8300\n",
      "--------------------------------------------------\n",
      "Epoch 23 [0/36] Loss: 0.5409 Acc: 87.50% LR: 0.000398\n",
      "\n",
      "Epoch 23/40\n",
      "Train Loss: 0.5050 | Train Acc: 0.8856\n",
      "Val Loss: 0.5739 | Val Acc: 0.8340\n",
      "--------------------------------------------------\n",
      "Epoch 24 [0/36] Loss: 0.4427 Acc: 93.75% LR: 0.000363\n",
      "\n",
      "Epoch 24/40\n",
      "Train Loss: 0.4637 | Train Acc: 0.9179\n",
      "Val Loss: 0.5919 | Val Acc: 0.8381\n",
      "--------------------------------------------------\n",
      "Epoch 25 [0/36] Loss: 0.3982 Acc: 96.88% LR: 0.000329\n",
      "\n",
      "Epoch 25/40\n",
      "Train Loss: 0.5005 | Train Acc: 0.8882\n",
      "Val Loss: 0.5617 | Val Acc: 0.8381\n",
      "--------------------------------------------------\n",
      "Epoch 26 [0/36] Loss: 0.4652 Acc: 93.75% LR: 0.000295\n",
      "\n",
      "Epoch 26/40\n",
      "Train Loss: 0.5005 | Train Acc: 0.8812\n",
      "Val Loss: 0.5840 | Val Acc: 0.8381\n",
      "--------------------------------------------------\n",
      "Epoch 27 [0/36] Loss: 0.6546 Acc: 84.38% LR: 0.000261\n",
      "\n",
      "Epoch 27/40\n",
      "Train Loss: 0.4939 | Train Acc: 0.8943\n",
      "Val Loss: 0.5903 | Val Acc: 0.8300\n",
      "--------------------------------------------------\n",
      "Early stopping after 27 epochs\n",
      "✅ Finished resnext50_32x4d | Best Val Accuracy: 0.8381\n",
      "------------------------------------------------------------\n",
      "\n",
      "🔁 Training with model: coatnet_0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Unknown model (coatnet_0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-31-2017013230.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Reinitialize model and move to device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mECGClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Redefine optimizer and scheduler for each model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipython-input-26-2577111882.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name, num_classes, dropout)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tf_efficientnetv2_s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/timm/models/_factory.py\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(model_name, pretrained, pretrained_cfg, pretrained_cfg_overlay, checkpoint_path, cache_dir, scriptable, exportable, no_jit, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unknown model (%s)'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mcreate_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_entrypoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unknown model (coatnet_0)"
     ]
    }
   ],
   "source": [
    "# 11. Try Multiple Models for Comparison - EfficientNet-B0, EfficientNetV2-S, ConvNeXt, ResNeXt\n",
    "model_names = [\n",
    "    'efficientnet_b0',\n",
    "    'tf_efficientnetv2_s',\n",
    "    'resnext50_32x4d',\n",
    "]\n",
    "\n",
    "comparison_results = {}\n",
    "\n",
    "for model_name in model_names:\n",
    "    print(f\"\\n🔁 Training with model: {model_name}\")\n",
    "\n",
    "    # Reinitialize model and move to device\n",
    "    model = ECGClassifier(model_name=model_name, num_classes=4).to(device)\n",
    "\n",
    "    # Redefine optimizer and scheduler for each model\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=8e-4,\n",
    "        weight_decay=0.01,\n",
    "        betas=(0.9, 0.999)\n",
    "    )\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=8e-4,\n",
    "        epochs=40,\n",
    "        steps_per_epoch=len(train_loader),\n",
    "        pct_start=0.1,\n",
    "        anneal_strategy='cos'\n",
    "    )\n",
    "\n",
    "    # Redefine scaler for mixed precision\n",
    "    scaler = torch.cuda.amp.GradScaler() if use_amp else None\n",
    "\n",
    "    # Train the model\n",
    "    result = train_model(train_loader, val_loader, epochs=40, patience=8)\n",
    "\n",
    "    # Store best val acc for comparison\n",
    "    comparison_results[model_name] = result['best_acc']\n",
    "\n",
    "    print(f\"✅ Finished {model_name} | Best Val Accuracy: {result['best_acc']:.4f}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# Summary of all model performances\n",
    "print(\"\\n📊 Model Performance Summary:\")\n",
    "for name, acc in comparison_results.items():\n",
    "    print(f\"{name}: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tuHM_iIL1QH5"
   },
   "outputs": [],
   "source": [
    "# 11. Training Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from pathlib import Path\n",
    "\n",
    "# Get the training metrics from results\n",
    "train_losses = results['train_losses']\n",
    "val_losses = results['val_losses']\n",
    "train_accs = results['train_accs']\n",
    "val_accs = results['val_accs']\n",
    "\n",
    "# Create visualization\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Loss curves\n",
    "epochs = range(1, len(train_losses) + 1)\n",
    "ax1.plot(epochs, train_losses, label='Training Loss', color='blue', linewidth=2)\n",
    "ax1.plot(epochs, val_losses, label='Validation Loss', color='red', linewidth=2)\n",
    "ax1.set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy curves\n",
    "ax2.plot(epochs, train_accs, label='Training Accuracy', color='blue', linewidth=2)\n",
    "ax2.plot(epochs, val_accs, label='Validation Accuracy', color='red', linewidth=2)\n",
    "ax2.set_title('Training and Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Learning rate schedule (approximate for OneCycleLR)\n",
    "# Since we can't track exact LR, we'll create an approximation\n",
    "max_lr = 8e-4\n",
    "total_epochs = len(train_losses)\n",
    "# OneCycleLR pattern: rise to max, then decay\n",
    "lr_schedule = []\n",
    "for i in range(total_epochs):\n",
    "    if i < total_epochs * 0.1:  # First 10% - warmup\n",
    "        lr = max_lr * (i / (total_epochs * 0.1))\n",
    "    else:  # Remaining 90% - cosine decay\n",
    "        progress = (i - total_epochs * 0.1) / (total_epochs * 0.9)\n",
    "        lr = max_lr * 0.5 * (1 + np.cos(np.pi * progress))\n",
    "    lr_schedule.append(lr)\n",
    "\n",
    "ax3.plot(epochs, lr_schedule, color='green', linewidth=2)\n",
    "ax3.set_title('Learning Rate Schedule (Approximate)', fontsize=14, fontweight='bold')\n",
    "ax3.set_xlabel('Epoch')\n",
    "ax3.set_ylabel('Learning Rate')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Training summary\n",
    "ax4.text(0.1, 0.8, f'Best Validation Accuracy: {results[\"best_acc\"]:.4f}',\n",
    "         fontsize=12, transform=ax4.transAxes, fontweight='bold')\n",
    "ax4.text(0.1, 0.7, f'Final Training Accuracy: {train_accs[-1]:.4f}',\n",
    "         fontsize=12, transform=ax4.transAxes)\n",
    "ax4.text(0.1, 0.6, f'Final Validation Accuracy: {val_accs[-1]:.4f}',\n",
    "         fontsize=12, transform=ax4.transAxes)\n",
    "ax4.text(0.1, 0.5, f'Total Epochs: {len(train_losses)}',\n",
    "         fontsize=12, transform=ax4.transAxes)\n",
    "ax4.text(0.1, 0.4, f'Early Stopping: {\"Yes\" if len(train_losses) < 40 else \"No\"}',\n",
    "         fontsize=12, transform=ax4.transAxes)\n",
    "ax4.set_title('Training Summary', fontsize=14, fontweight='bold')\n",
    "ax4.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gG0ZAj-z1QqB"
   },
   "outputs": [],
   "source": [
    "# 12. Comprehensive Model Evaluation\n",
    "print(\"Loading best model...\")\n",
    "\n",
    "# Model path - use the correct directory structure\n",
    "models_dir = MODELS_DIR\n",
    "model_path = models_dir / 'best_ecg_model.pth'\n",
    "\n",
    "# Check if model file exists\n",
    "if model_path.exists():\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"✅ Model loaded successfully!\")\n",
    "    print(f\"Best validation accuracy: {checkpoint['best_acc']:.4f}\")\n",
    "\n",
    "    # Final evaluation\n",
    "    print(\"\\nEvaluating model on validation set...\")\n",
    "    val_loss, val_acc, y_pred, y_true = validate_epoch(val_loader)\n",
    "\n",
    "    # Classification report\n",
    "    label_names = ['Abnormal HB', 'MI', 'Normal', 'PMI']\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FINAL CLASSIFICATION REPORT\")\n",
    "    print(\"=\"*60)\n",
    "    print(classification_report(y_true, y_pred, target_names=label_names, digits=4))\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=label_names, yticklabels=label_names,\n",
    "                cbar_kws={'label': 'Count'})\n",
    "    plt.title('Confusion Matrix - ECG Classification', fontsize=16, fontweight='bold')\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Additional metrics\n",
    "    from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(y_true, y_pred, average=None)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DETAILED METRICS BY CLASS\")\n",
    "    print(\"=\"*60)\n",
    "    for i, label in enumerate(label_names):\n",
    "        print(f\"{label:12} | Precision: {precision[i]:.4f} | Recall: {recall[i]:.4f} | F1: {f1[i]:.4f} | Support: {support[i]}\")\n",
    "\n",
    "    print(f\"\\nOverall Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Macro Average F1: {np.mean(f1):.4f}\")\n",
    "    print(f\"Weighted Average F1: {np.average(f1, weights=support):.4f}\")\n",
    "\n",
    "else:\n",
    "    print(f\"❌ Model file not found at: {model_path}\")\n",
    "    print(\"Available files in models directory:\")\n",
    "    if models_dir.exists():\n",
    "        for file in models_dir.iterdir():\n",
    "            print(f\"  - {file.name}\")\n",
    "    else:\n",
    "        print(\"  Models directory doesn't exist!\")\n",
    "\n",
    "    print(\"\\nUsing current model state for evaluation...\")\n",
    "    val_loss, val_acc, y_pred, y_true = validate_epoch(val_loader)\n",
    "\n",
    "    # Classification report with current model\n",
    "    label_names = ['Abnormal HB', 'MI', 'Normal', 'PMI']\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CLASSIFICATION REPORT (Current Model State)\")\n",
    "    print(\"=\"*60)\n",
    "    print(classification_report(y_true, y_pred, target_names=label_names, digits=4))\n",
    "\n",
    "print(\"\\n🎯 Model evaluation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a9sd3RQS4013"
   },
   "outputs": [],
   "source": [
    "# 13. Clinical Report Generation\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "class_map = {\n",
    "    0: (\"Abnormal Heartbeat\", \"Possible arrhythmia or irregular rhythm. Recommend further cardiological evaluation.\"),\n",
    "    1: (\"Myocardial Infarction\", \"ECG pattern consistent with myocardial infarction. Urgent clinical attention advised.\"),\n",
    "    2: (\"Normal Sinus Rhythm\", \"Normal ECG. No abnormalities detected.\"),\n",
    "    3: (\"History of Myocardial Infarction\", \"Signs of previous infarction. Regular follow-up recommended.\")\n",
    "}\n",
    "\n",
    "def generate_text_report(test_id, prediction_idx, save_dir):\n",
    "    date_str = datetime.now().strftime(\"%Y‑%m‑%d\")\n",
    "    diagnosis, interpretation = class_map[prediction_idx]\n",
    "\n",
    "    content = f\"\"\"Test ID: {test_id}\n",
    "Date: {date_str}\n",
    "\n",
    "Automated Diagnosis\n",
    "-------------------\n",
    "{diagnosis}\n",
    "\n",
    "Clinical Interpretation\n",
    "-----------------------\n",
    "{interpretation}\n",
    "\"\"\"\n",
    "\n",
    "    report_path = save_dir / f\"{test_id}.txt\"\n",
    "    with open(report_path, 'w') as f:\n",
    "        f.write(content)\n",
    "    return diagnosis\n",
    "\n",
    "\n",
    "REPORTS_DIR.mkdir(exist_ok=True)\n",
    "summary_data = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Use your test loader, or raw paths like test_paths\n",
    "test_ds = ECGImageDataset(TEST_DIR, transform=get_validation_transforms())\n",
    "test_loader = DataLoader(test_ds, batch_size=1, shuffle=False)\n",
    "\n",
    "print(\"Generating reports...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img, _, path_str in tqdm(test_loader):\n",
    "      img = img.to(device)\n",
    "      path = Path(path_str[0])\n",
    "      test_id = path.stem\n",
    "\n",
    "      start_time = time.time()\n",
    "\n",
    "      # Prediction\n",
    "      output = model(img)\n",
    "      pred_idx = output.argmax(1).item()\n",
    "\n",
    "      end_time = time.time()\n",
    "      exec_time = round(end_time - start_time, 4)  # seconds\n",
    "\n",
    "      # Save report\n",
    "      diagnosis = generate_text_report(test_id, pred_idx, REPORTS_DIR)\n",
    "\n",
    "      # Append to summary\n",
    "      summary_data.append({\n",
    "          \"Test ID\": test_id,\n",
    "          \"Prediction Class\": pred_idx,\n",
    "          \"Diagnosis\": class_map[pred_idx][0],\n",
    "          \"Execution Time (s)\": exec_time\n",
    "      })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_df.to_csv(REPORTS_DIR / \"ecg_summary.csv\", index=False)\n",
    "print(\"✅ Summary CSV saved at:\", REPORTS_DIR / \"ecg_summary.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vMhYfqb07B9v"
   },
   "outputs": [],
   "source": [
    "# 14. ROC Curve Analysis with Enhanced Visualization\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def plot_roc_curves(model, dataloader, n_classes=4):\n",
    "    model.eval()\n",
    "    all_labels, all_probs = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels, _ in dataloader:\n",
    "            imgs = imgs.to(device)\n",
    "            outputs = model(imgs)\n",
    "            probs = F.softmax(outputs, dim=1).cpu().numpy()\n",
    "            all_probs.extend(probs)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Binarize the labels\n",
    "    y_true = label_binarize(all_labels, classes=list(range(n_classes)))\n",
    "    y_score = np.array(all_probs)\n",
    "\n",
    "    fpr, tpr, roc_auc = {}, {}, {}\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_true[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    colors = ['red', 'green', 'blue', 'purple']\n",
    "    labels = ['Abnormal Heartbeat', 'Myocardial Infarction', 'Normal', 'PMI']\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        plt.plot(fpr[i], tpr[i], color=colors[i],\n",
    "                 label=f'{labels[i]} (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Multi-Class ROC Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example\n",
    "plot_roc_curves(model, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yGzAXJwf7u4H"
   },
   "outputs": [],
   "source": [
    "# 15. Grad-CAM Visualization Enhancement\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as T\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "\n",
    "def batch_generate_gradcams(model, dataset, output_dir, method='GradCAM'):\n",
    "    model.eval()\n",
    "\n",
    "    # Choose the correct layer for EfficientNetV2-S\n",
    "    target_layer = model.backbone.blocks[-1]\n",
    "\n",
    "    cam_algorithm = eval(method)\n",
    "    cam = cam_algorithm(model=model, target_layers=[target_layer])\n",
    "\n",
    "    print(f\"Generating Grad-CAMs for {len(dataset)} samples...\")\n",
    "\n",
    "    for idx in tqdm(range(len(dataset))):\n",
    "        try:\n",
    "            image_tensor, label, path = dataset[idx]\n",
    "\n",
    "            input_tensor = image_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "            # Run CAM\n",
    "            grayscale_cam = cam(input_tensor=input_tensor,\n",
    "                                targets=[ClassifierOutputTarget(label)])[0]\n",
    "\n",
    "            # Convert image for overlay\n",
    "            img_np = image_tensor.permute(1, 2, 0).cpu().numpy()\n",
    "            img_np = (img_np - img_np.min()) / (img_np.max() - img_np.min())\n",
    "\n",
    "            cam_image = show_cam_on_image(img_np, grayscale_cam, use_rgb=True)\n",
    "\n",
    "            # Save CAM image\n",
    "            file_name = Path(path).stem + f'_class{label}.png'\n",
    "            save_path = output_dir / file_name\n",
    "            Image.fromarray(cam_image).save(save_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed for index {idx} ({path}): {e}\")\n",
    "\n",
    "    print(\"✅ Grad-CAM generation complete.\")\n",
    "\n",
    "# === Usage ===\n",
    "gradcam_dir = BASE_DIR / 'gradcam_outputs'\n",
    "gradcam_dir.mkdir(exist_ok=True)\n",
    "batch_generate_gradcams(model, test_ds, gradcam_dir)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1e1e43b734c044d494b119dbf8db2c29": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_edebf3fad31e41e1ace8a7168ea06582",
      "placeholder": "​",
      "style": "IPY_MODEL_8e488f9a3f694e9c84114576293c5c65",
      "value": "model.safetensors: 100%"
     }
    },
    "1fbf668f1bc44a41ab4909c625281486": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "242617d20f3e47f485335eeb80b3d65c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7664301a89e143aa86d981e2c66a1b89",
      "placeholder": "​",
      "style": "IPY_MODEL_e0a28c0e5e504a71a7d7d0b99e8851ad",
      "value": " 100M/100M [00:00&lt;00:00, 144MB/s]"
     }
    },
    "32bbbed09ced4246bf41c6f3f4460c70": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "33e05f1233f34951aae9d04a9550e0d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1e1e43b734c044d494b119dbf8db2c29",
       "IPY_MODEL_4d8a77048d6b4b14be4bda8f5d52357a",
       "IPY_MODEL_6446fa70ea2f4960a5fedcca206f4a80"
      ],
      "layout": "IPY_MODEL_939170c5f5a94559b9b409b43ff11619"
     }
    },
    "41ab583f11604f7582539116c500d4c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "485d839fde4e409b81c7036769eab8b4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d8a77048d6b4b14be4bda8f5d52357a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1fbf668f1bc44a41ab4909c625281486",
      "max": 114374272,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b9b61a45a36041c0ace462f0be78cf7c",
      "value": 114374272
     }
    },
    "5c7698a44af54eaf9ba87077fabcaee2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "637e60293ba44f15a5b2c1af0b2073c4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6446fa70ea2f4960a5fedcca206f4a80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_637e60293ba44f15a5b2c1af0b2073c4",
      "placeholder": "​",
      "style": "IPY_MODEL_c916e0d7ca42472abfa7f53f20754ad0",
      "value": " 114M/114M [00:00&lt;00:00, 154MB/s]"
     }
    },
    "691c18d74a974823a187dd82c6942f2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_32bbbed09ced4246bf41c6f3f4460c70",
      "placeholder": "​",
      "style": "IPY_MODEL_5c7698a44af54eaf9ba87077fabcaee2",
      "value": "model.safetensors: 100%"
     }
    },
    "6becdea84fce4e50b202393c4f127511": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_485d839fde4e409b81c7036769eab8b4",
      "max": 100417784,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8527ca023b3c49a18c1d6015b9416ed5",
      "value": 100417784
     }
    },
    "7664301a89e143aa86d981e2c66a1b89": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8527ca023b3c49a18c1d6015b9416ed5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8e488f9a3f694e9c84114576293c5c65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "939170c5f5a94559b9b409b43ff11619": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b9b61a45a36041c0ace462f0be78cf7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c916e0d7ca42472abfa7f53f20754ad0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e0a28c0e5e504a71a7d7d0b99e8851ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e5d3ebcfc36e4fcc9fd6d336905c7b68": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_691c18d74a974823a187dd82c6942f2a",
       "IPY_MODEL_6becdea84fce4e50b202393c4f127511",
       "IPY_MODEL_242617d20f3e47f485335eeb80b3d65c"
      ],
      "layout": "IPY_MODEL_41ab583f11604f7582539116c500d4c0"
     }
    },
    "edebf3fad31e41e1ace8a7168ea06582": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
